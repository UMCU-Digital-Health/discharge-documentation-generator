{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use DEDUCE to pseudonomise text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hashlib import sha256\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from deduce import Deduce\n",
    "from IPython.display import display\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "deduce = Deduce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_deduce(df: pd.DataFrame, col_name: str):\n",
    "    df[col_name] = (\n",
    "        df[col_name]\n",
    "        .fillna(\"\")  # some None values, which are not handled by deduce\n",
    "        .progress_apply(\n",
    "            lambda x: deduce.deidentify(x, disabled={\"dates\"}).deidentified_text\n",
    "        )\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path(\n",
    "    \"/mapr/administratielast/administratielast_datamanager/ontslagdocumentatie/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply DEDUCE to Metavision data\n",
    "The code below applies DEDUCE to the metavision data. However, since the Metavision data is not completely loaded into the dataplatform, we need to work with a separate export, see [Apply DEDUCE to new Metavision data](#apply-deduce-to-new-metavision-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and apply DEDUCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metavision_data = pd.read_json(\n",
    "    data_folder / \"metavision_extraction.json\",\n",
    "    convert_dates=[\"period_start\", \"period_end\", \"effectiveDateTime\"],\n",
    "    dtype={\"subject_Patient_value\": str},\n",
    ")\n",
    "metavision_data = apply_deduce(metavision_data, \"valueString\")\n",
    "display(metavision_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save pseudonomised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metavision_data[[\"pseudo_id\", \"subject_Patient_value\"]].drop_duplicates().to_csv(\n",
    "    data_folder / \"pseudo_table.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metavision_data.drop(columns=\"subject_Patient_value\").to_csv(\n",
    "    data_folder / \"pseudonomised_metavision_data.csv\",\n",
    "    index=False,\n",
    ")\n",
    "metavision_data.drop(columns=\"subject_Patient_value\").to_parquet(\n",
    "    data_folder / \"pseudonomised_metavision_data.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply DEDUCE to HiX data\n",
    "\n",
    "### Load discharge letters and apply DEDUCE and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_and_save_deduce_discharge_docs_dp(\n",
    "    file_name, save=True, delete_original=False\n",
    "):\n",
    "    # input must be a json file\n",
    "    file_path = data_folder / file_name\n",
    "    discharge_data = pd.read_json(\n",
    "        Path(file_path).with_suffix(\".json\"),\n",
    "        convert_dates=[\"period_start\", \"period_end\", \"created\"],\n",
    "        dtype={\"subject_Patient_value\": str},\n",
    "    )\n",
    "    discharge_data = apply_deduce(discharge_data, \"content_attachment1_plain_data\")\n",
    "    display(discharge_data)\n",
    "\n",
    "    if save:\n",
    "        # pseudo keylist table\n",
    "        discharge_data[[\"pseudo_id\", \"subject_Patient_value\"]].drop_duplicates().to_csv(\n",
    "            data_folder / (file_name + \"pseudo_table.csv\"),\n",
    "            index=False,\n",
    "        )\n",
    "        print(\"Pseudo keylist table saved as \" + file_name + \"pseudo_table.csv\")\n",
    "        # save discharge data to csv\n",
    "        discharge_data.drop(columns=\"subject_Patient_value\").to_csv(\n",
    "            data_folder / (\"pseudonomised_\" + file_name + \".csv\"),\n",
    "            index=False,\n",
    "        )\n",
    "        print(\"Pseudonomised discharge data saved as \" + file_name + \".csv\")\n",
    "        # save discharge data to parquet\n",
    "        discharge_data.drop(columns=\"subject_Patient_value\").to_parquet(\n",
    "            data_folder / (\"pseudonomised_\" + file_name + \".parquet\"),\n",
    "        )\n",
    "        print(\"Pseudonomised discharge data saved as \" + file_name + \".parquet\")\n",
    "    if delete_original:\n",
    "        (Path(file_path).with_suffix(\"json\")).unlink()\n",
    "        print(\"Original discharge data file deleted\")\n",
    "\n",
    "\n",
    "# apply_and_save_deduce_discharge_docs_dp(\"hix_discharge_docs\", save=True)\n",
    "# apply_and_save_deduce_discharge_docs_dp(\"HiX_discharge_docs_2\", save=True)\n",
    "apply_and_save_deduce_discharge_docs_dp(\"HiX_discharge_docs_3\", save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load patient files and apply DEDUCE and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_and_save_deduce_patient_files_hix(\n",
    "    file_name, save=True, delete_original=False\n",
    "):\n",
    "    file_path = data_folder / file_name\n",
    "    hix_patient_files = pd.read_json(\n",
    "        Path(file_path).with_suffix(\".json\"),\n",
    "        convert_dates=[\"period_start\", \"period_end\", \"created\", \"authored\"],\n",
    "        dtype={\"subject_Patient_value\": str},\n",
    "    )\n",
    "    hix_patient_files = apply_deduce(hix_patient_files, \"item_answer_value_valueString\")\n",
    "    display(hix_patient_files)\n",
    "\n",
    "    if save:\n",
    "        # pseudo keylist table\n",
    "        hix_patient_files[\n",
    "            [\"pseudo_id\", \"subject_Patient_value\"]\n",
    "        ].drop_duplicates().to_csv(\n",
    "            data_folder / (file_name + \"pseudo_table.csv\"),\n",
    "            index=False,\n",
    "        )\n",
    "        print(\"Pseudo keylist table saved as \" + file_name + \"pseudo_table.csv\")\n",
    "        # save discharge data to csv\n",
    "        hix_patient_files.drop(columns=\"subject_Patient_value\").to_csv(\n",
    "            data_folder / (\"pseudonomised_\" + file_name + \".csv\"),\n",
    "            index=False,\n",
    "        )\n",
    "        print(\"Pseudonomised discharge data saved as \" + file_name + \".csv\")\n",
    "        # save discharge data to parquet\n",
    "        hix_patient_files.drop(columns=\"subject_Patient_value\").to_parquet(\n",
    "            data_folder / (\"pseudonomised_\" + file_name + \".parquet\"),\n",
    "        )\n",
    "        print(\"Pseudonomised discharge data saved as \" + file_name + \".parquet\")\n",
    "    if delete_original:\n",
    "        (Path(file_path).with_suffix(\"json\")).unlink()\n",
    "        print(\"Original discharge data file deleted\")\n",
    "\n",
    "    # apply_and_save_deduce_patient_files_hix(\"HiX_patient_files_2\", save=True)\n",
    "apply_and_save_deduce_patient_files_hix(\"HiX_patient_files_3\", save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply DEDUCE to new metavision data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and fix types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metavision_admissions = pd.read_csv(\n",
    "    data_folder / \"2024-01-09 MV6 admissions LMM.csv\",\n",
    "    sep=\";\",\n",
    "    parse_dates=[\"AddmissionDate\", \"DischargeDate\"],\n",
    "    dtype={\"HospitalNumber\": str},\n",
    ")\n",
    "metavision_freetext = pd.read_csv(\n",
    "    data_folder / \"2024-01-09 MV6 freetexts LMM.csv\",\n",
    "    sep=\";\",\n",
    "    parse_dates=[\"Time\", \"ValidationTime\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pseudo_id and fix columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metavision_admissions[\"pseudo_id\"] = (\n",
    "    metavision_admissions[\"HospitalNumber\"].astype(str) + \"aiva\"\n",
    ").apply(lambda x: sha256(x.encode(\"utf-16le\")).hexdigest())\n",
    "\n",
    "metavision_admissions = metavision_admissions.rename(\n",
    "    columns={\"HospitalNumber\": \"subject_Patient_value\"}\n",
    ").drop(columns=[\"LogicalUnitID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metavision_freetext = metavision_freetext.drop(columns=[\"LogicalUnitID\", \"CategoryID\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge datasets and apply DEDUCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metavision_new = metavision_admissions.merge(metavision_freetext, on=\"PatientID\").drop(\n",
    "    columns=\"PatientID\"\n",
    ")\n",
    "metavision_new = apply_deduce(metavision_new, \"Value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save pseudonomised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metavision_new[[\"pseudo_id\", \"subject_Patient_value\"]].drop_duplicates().to_csv(\n",
    "    data_folder / \"new_metavision_pseudo_table.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metavision_new.drop(columns=\"subject_Patient_value\").to_csv(\n",
    "    data_folder / \"pseudonomised_new_metavision_data.csv\", index=False\n",
    ")\n",
    "metavision_new.drop(columns=\"subject_Patient_value\").to_parquet(\n",
    "    data_folder / \"pseudonomised_new_metavision_data.parquet\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "discharge_documentation_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
