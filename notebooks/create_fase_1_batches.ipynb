{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from pathlib import Path\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "import os\n",
    "from discharge_docs.prompts.prompt import (\n",
    "    load_prompts,\n",
    "    load_template_prompt,\n",
    ")\n",
    "\n",
    "os.environ[\"TIKTOKEN_CACHE_DIR\"] = \"\"\n",
    "\n",
    "pd.options.display.max_colwidth = 1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voor de nieuwe batch met cardio patiënten:\n",
    "\n",
    "\n",
    "student1 had de eerste 2 dossiers al gedaan\n",
    "student2 had de eerste 5 dossiers al gedaan\n",
    "\n",
    "Besluiten voor nieuwe verdeling, met cardio patiënten:\n",
    "- Excludeer de eerste 2 patiënten van student1, en de eerste 5 van student2\n",
    "- Voor de IC: focus op patiënten met een opnameduur van max 5 dagen\n",
    "- Voor de NICU: sommige brieven klopten niet, handmatig eruit filteren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_ids_student_1_done = [302, 332]\n",
    "enc_ids_student_2_done = [302, 332, 361, 11, 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get current file path\n",
    "current_path = Path.cwd().parent\n",
    "data_path = current_path / \"data\" / \"processed\"\n",
    "metavision_path = \"metavision_data_april_dp.parquet\"\n",
    "hix_path = \"HiX_CAR_data_pre_pilot.parquet\"\n",
    "df_discharge_metavision = pd.read_parquet(data_path / metavision_path)\n",
    "df_discharge_hix = pd.read_parquet(data_path / hix_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are any values for enc_id in df_discharge_metavision that are in df_discharge_hix\n",
    "df_discharge_hix_enc_ids = df_discharge_hix[\"enc_id\"].unique()\n",
    "df_discharge_metavision_enc_ids = df_discharge_metavision[\"enc_id\"].unique()\n",
    "common_enc_ids = set(df_discharge_metavision_enc_ids).intersection(\n",
    "    set(df_discharge_hix_enc_ids)\n",
    ")\n",
    "print(f\"Common enc_ids: {common_enc_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_discharge = pd.concat([df_discharge_metavision, df_discharge_hix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load prompts:\n",
    "user_prompt, system_prompt = load_prompts()\n",
    "template_prompt_NICU = load_template_prompt(\"NICU\")\n",
    "template_prompt_IC = load_template_prompt(\"IC\")\n",
    "template_prompt_CAR = load_template_prompt(\"CAR\")\n",
    "template_prompt_PSY = load_template_prompt(\"PSY\")\n",
    "template_prompt_dict = {\n",
    "    \"nicu\": template_prompt_NICU,\n",
    "    \"ic\": template_prompt_IC,\n",
    "    \"car\": template_prompt_CAR,\n",
    "    \"psy\": template_prompt_PSY,\n",
    "    \"demo\": template_prompt_NICU,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voeg token lenth toe:\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "encs = []\n",
    "longer_encs = []\n",
    "for enc_id in np.sort(df_discharge[\"enc_id\"].unique()):\n",
    "    patient_data_string = \" \".join(\n",
    "        df_discharge[df_discharge[\"enc_id\"] == enc_id][\"value\"]\n",
    "    )\n",
    "    # print(\n",
    "    #     f\"The number of tokens in encounter {enc_id}: {len(encoding.encode(patient_data_string))} \"+\n",
    "    #     f\"with length of stay: {df_discharge[df_discharge.enc_id == enc_id].length_of_stay.unique()}\"\n",
    "    # )\n",
    "    template_prompt_length = len(\n",
    "        encoding.encode(user_prompt + system_prompt + template_prompt_NICU)\n",
    "    )\n",
    "    if (len(encoding.encode(patient_data_string)) + template_prompt_length) < 110000:\n",
    "        encs.append(enc_id)\n",
    "    else:\n",
    "        longer_encs.append(enc_id)\n",
    "\n",
    "# print(encs)\n",
    "print(longer_encs)  # remove these from batching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the enc_ids that are too long for GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hardcoded such that the assigment remains reproducible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longer_ids_hardcoded = [\n",
    "    0,\n",
    "    1,\n",
    "    2,\n",
    "    3,\n",
    "    5,\n",
    "    6,\n",
    "    21,\n",
    "    1002,\n",
    "    1010,\n",
    "    1018,\n",
    "    1023,\n",
    "    1028,\n",
    "    1036,\n",
    "    1041,\n",
    "    1045,\n",
    "    1063,\n",
    "    1070,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter records that are too long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"enc ids before filter step: {df_discharge['enc_id'].nunique()}\")\n",
    "df_discharge = df_discharge[~df_discharge[\"enc_id\"].isin(longer_ids_hardcoded)]\n",
    "print(f\"enc ids after filter step: {df_discharge['enc_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter records that have been marked already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"enc ids before filter step: {df_discharge['enc_id'].nunique()}\")\n",
    "df_discharge = df_discharge[~df_discharge[\"enc_id\"].isin(enc_ids_student_1_done)]\n",
    "print(f\"enc ids after filter step: {df_discharge['enc_id'].nunique()}\")\n",
    "df_discharge = df_discharge[~df_discharge[\"enc_id\"].isin(enc_ids_student_2_done)]\n",
    "print(f\"enc ids after filter step: {df_discharge['enc_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_discharge_filtered = df_discharge[df_discharge[\"description\"] == \"Ontslagbrief\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IC = df_discharge_filtered[\n",
    "    df_discharge_filtered[\"department\"] == \"Intensive Care Centrum\"\n",
    "]\n",
    "print(f\"number of IC encounters: {df_IC['enc_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NICU = df_discharge_filtered[df_discharge_filtered[\"department\"] == \"Neonatologie\"]\n",
    "print(f\"number of NICU encounters: {df_NICU['enc_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Cardio = df_discharge_filtered[df_discharge_filtered[\"department\"] == \"CAR\"]\n",
    "print(f\"number of CAR encounters: {df_Cardio['enc_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NICU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NICU ids for the first pilot round should be filtered out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_nicu_ids = df_NICU[\"enc_id\"].unique()\n",
    "first_ids_nicu = [201, 41, 244]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NICU discharge letter set contains some incomplete letters, so we will filter them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclusion_strings = [\"..\", \"G-schijf\", \"G-\", \"G schijf\"]\n",
    "\n",
    "incomplete_nicu_ids = []\n",
    "for idx, row in df_NICU.iterrows():\n",
    "    if any(substring in row[\"value\"] for substring in exclusion_strings):\n",
    "        incomplete_nicu_ids.append(row[\"enc_id\"])\n",
    "\n",
    "print(f\"# incomplete NICU ids: {len(incomplete_nicu_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_nicu_ids = (\n",
    "    set(potential_nicu_ids) - set(first_ids_nicu) - set(incomplete_nicu_ids)\n",
    ")\n",
    "df_NICU = df_NICU[df_NICU[\"enc_id\"].isin(remaining_nicu_ids)]\n",
    "print(f\"number of NICU encounters after filtering: {df_NICU['enc_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter further based on length and inspect all manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, letter in df_NICU.sort_values(\"enc_id\").iterrows():\n",
    "    print(f\"id: {letter['enc_id']}, length: {len(letter['value'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NICU[df_NICU[\"enc_id\"] == 37][[\"enc_id\", \"value\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_nicu_ids = [8, 35, 301, 302, 369, 476]\n",
    "\n",
    "df_NICU_processed = df_NICU[~df_NICU[\"enc_id\"].isin(invalid_nicu_ids)]\n",
    "print(\n",
    "    f\"Number of NICU encounters after removing invalid ids: {df_NICU_processed['enc_id'].nunique()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IC looks good. Can use random samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IC ids for the first pilot round should be filtered out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_ic_ids = df_IC[\"enc_id\"].unique()\n",
    "fist_ids_ic = [373, 304, 437, 24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_ic_ids = set(potential_ic_ids) - set(fist_ids_ic)\n",
    "df_IC = df_IC[df_IC[\"enc_id\"].isin(remaining_ic_ids)]\n",
    "print(f\"number of IC encounters after filtering: {df_IC['enc_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out IC stays of more than 5 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IC = df_IC[df_IC[\"length_of_stay\"] <= 5]\n",
    "print(f\"number of IC encounters after filtering: {df_IC['enc_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checked the length, no nearly empty reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, letter in df_IC.sort_values(\"enc_id\").iterrows():\n",
    "    print(f\"id: {letter['enc_id']}, length: {len(letter['value'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IC[df_IC[\"enc_id\"] == 225][[\"enc_id\", \"value\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IC_processed = df_IC\n",
    "print(\n",
    "    f\"Number of IC encounters after removing invalid ids: {df_IC_processed['enc_id'].nunique()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cardio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Cardio[df_Cardio[\"enc_id\"] == df_Cardio[\"enc_id\"].unique()[0]][[\"enc_id\", \"value\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Cardio[df_Cardio[\"value\"].apply(lambda x: len(x)) < 1000][\"enc_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, letter in df_Cardio.sort_values(\"enc_id\").iterrows():\n",
    "    print(f\"id: {letter['enc_id']}, length: {len(letter['value'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_cardio_ids = [1003]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter voorlopige ontslagbrieven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Cardio[df_Cardio[\"value\"].str.contains(\"voorlopige ontslagbrief\")][\"enc_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_cardio_ids += [1039, 1042]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Cardio[df_Cardio[\"enc_id\"] == df_Cardio[\"enc_id\"].unique()[30]][[\"enc_id\", \"value\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Number of Cardio encounters before removing invalid ids: {df_Cardio['enc_id'].nunique()}\"\n",
    ")\n",
    "df_Cardio_processed = df_Cardio[~df_Cardio[\"enc_id\"].isin(invalid_cardio_ids)]\n",
    "print(\n",
    "    f\"Number of Cardio encounters after removing invalid ids: {df_Cardio_processed['enc_id'].nunique()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Eerste idee voor het sampelen van de ontslagbrieven:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We nemen een sample van 100 EPD/ontslagbrieven combinaties, 1 willekeurige, 33 van elke afdeling. Uniform verdeeld qua lengte tussen het kortste dossier en het langst acceptabele dossier voor GPT. 1 willekeurige wordt van tevoren door een arts geannoteerd, te gebruiken bij de kickoff. 6 (2 van elke afdeling) worden gebruikt voor de burn-in en dus gescoord door alle 3 de studenten en geëvalueerd tijdens de tweede sessie. De overige 93 (31 per afdeling) willen we verdelen over batches zodat mochten we niet tot de 100 komen in totaal we toch voldoende overlap tussen de studenten hebben en de studenten zowel de GPT als art brief die bij een opname hoort hebben gezien.\n",
    "\n",
    "Per batch van 30: 6 overlappende (2 elke afdeling) en 3x8 unieke per student. Deze in een random volgorde gezet over de GPT en arts brieven, dus per batch 2*(6+8) = 28 te annoteren brieven per student in willekeurige volgorde. de laatste brief kan er bij een willekeurige student bij komen. Deze batches kunnen allemaal van tevoren worden gegenereerd zodat de studenten niet hoeven te wachten na een batch, maar zodat er wel voldoende overlap blijft bestaan en zowel de GPT en arts brief door dezelfde student zijn beoordeeld binnen een batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aangepaste versie**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doordat er wat dingen anders zijn gelopen dan in het initiele plan, is de opzet van het batchen ook wat veranderd. Het idee is dat de gewenste overlap gelijk blijft: 20%. We hebben voor de kickoff patient een nep patient gebruikt, dus deze hoefde niet gexcludeerd te worden. We hebben in eerste instantie 3 IDS van de NICU voorgelegd en 4 van de IC. Deze hebben we voor het maken van de volgende batches eruit gefilterd. Voor het samplen gebruiken we ook niet de token length van het dossier, maar de LoS als proxy. Dit zorgt ervoor dat we niet met bins hoeven werken.\n",
    "\n",
    "In de nieuwe methode worden eerst dossiers uniform over de LoS gesampled en deze daarna over de studenten verdeeld, dusdanig dat ~elke vijfde brief van elke afdeling overlapt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Derde versie**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cardio er nu bij en extra filterstappen voor NICU en IC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ordered_id_list(df_los):\n",
    "    \"\"\"Return the list of patient IDs for that has been sampled uniformly based on LoS\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_los : pd.DataFrame\n",
    "        dataframe containing enc_id and\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a list of NICU letters in which order they are to be divided among the students\n",
    "    # First, from the dataframe with enc_id and length of stay, create a dict for which the\n",
    "    # keys are the length and the value a list of enc_ids with that length\n",
    "    # shuffle the list of enc_ids for each length\n",
    "\n",
    "    length_enc_id_dict = {}\n",
    "    for idx, row in df_los.iterrows():\n",
    "        length = row[\"length_of_stay\"]\n",
    "        if length not in length_enc_id_dict:\n",
    "            length_enc_id_dict[length] = []\n",
    "        length_enc_id_dict[length].append(row[\"enc_id\"])\n",
    "\n",
    "    for key in length_enc_id_dict:\n",
    "        random.shuffle(length_enc_id_dict[key])\n",
    "\n",
    "    # Now randomly sample one of the keys in the length_enc_id_dict and pop the first\n",
    "    # element. If the list is empty, remove the key from the dict. Add the popped element\n",
    "    # to the ordered_id list. Repeat until the dict is empty\n",
    "\n",
    "    ordered_ids = []\n",
    "    while length_enc_id_dict:\n",
    "        length = random.choice(list(length_enc_id_dict.keys()))\n",
    "        ordered_ids.append(length_enc_id_dict[length].pop(0))\n",
    "        if not length_enc_id_dict[length]:\n",
    "            length_enc_id_dict.pop(length)\n",
    "\n",
    "    return ordered_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a list with students, and a dict with departments and ids\n",
    "# divide the ids among the students such that every overlap_rounds all students get the same\n",
    "# id for the department\n",
    "\n",
    "\n",
    "def divide_ids_among_students(students, department_id_dict, overlap_rounds=5):\n",
    "    \"\"\"Take a list with students, and a dict with departments and ids\n",
    "    divide the ids among the students such that every overlap_rounds all\n",
    "    students get the same id for the department.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    students : list\n",
    "        list of students\n",
    "    department_id_dict : dict\n",
    "        dict with department as key and list of ids as value\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        dict with student as key and list of ids as value\n",
    "    \"\"\"\n",
    "\n",
    "    student_id_dict = {}\n",
    "    student_dept_dict = {}\n",
    "    for student in students:\n",
    "        student_id_dict[student] = []\n",
    "        student_dept_dict[student] = []\n",
    "\n",
    "    # For determining when an overlapping id needs to be assigned\n",
    "    department_overlap_dict = {}\n",
    "    for dep in department_id_dict:\n",
    "        department_overlap_dict[dep] = overlap_rounds\n",
    "\n",
    "    empty_dep = False\n",
    "    while not empty_dep:\n",
    "\n",
    "        for id in department_id_dict:\n",
    "            if department_overlap_dict[id] // overlap_rounds > 0:\n",
    "\n",
    "                id_to_add = department_id_dict[id].pop(0)\n",
    "                department_overlap_dict[id] -= overlap_rounds\n",
    "\n",
    "                # stop when one of the departments has no more ids to assign\n",
    "                if not department_id_dict[id]:\n",
    "                    empty_dep = True\n",
    "\n",
    "                for student in students:\n",
    "                    student_id_dict[student].append(id_to_add)\n",
    "                    student_dept_dict[student].append(id)\n",
    "            else:\n",
    "                for student in students:\n",
    "\n",
    "                    id_to_add = department_id_dict[id].pop(0)\n",
    "                    department_overlap_dict[id] += 1\n",
    "\n",
    "                    # stop when one of the departments has no more ids to assign\n",
    "                    if not department_id_dict[id]:\n",
    "                        empty_dep = True\n",
    "                        break\n",
    "\n",
    "                    student_id_dict[student].append(id_to_add)\n",
    "                    student_dept_dict[student].append(id)\n",
    "\n",
    "    return student_id_dict, student_dept_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To ensure consistency\n",
    "random.seed(1000)\n",
    "\n",
    "nicu_ordered = create_ordered_id_list(df_NICU_processed)\n",
    "ic_ordered = create_ordered_id_list(df_IC_processed)\n",
    "cardio_ordered = create_ordered_id_list(df_Cardio_processed)\n",
    "\n",
    "print(f\"Length of NICU ordered list: {len(nicu_ordered)}\")\n",
    "print(f\"Length of IC ordered list: {len(ic_ordered)}\")\n",
    "print(f\"Length of Cardio ordered list: {len(cardio_ordered)}\")\n",
    "\n",
    "\n",
    "department_dict = {\"NICU\": nicu_ordered, \"IC\": ic_ordered, \"CAR\": cardio_ordered}\n",
    "students = [\"student_1\", \"student_2\"]\n",
    "\n",
    "id_assignment, dpt_assignment = divide_ids_among_students(students, department_dict, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_student_1 = id_assignment[\"student_1\"]\n",
    "dpt_student_1 = dpt_assignment[\"student_1\"]\n",
    "print(ids_student_1)\n",
    "print(dpt_student_1)\n",
    "ids_student_2 = id_assignment[\"student_2\"]\n",
    "dpt_student_2 = dpt_assignment[\"student_2\"]\n",
    "print(ids_student_2)\n",
    "print(dpt_student_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ids_student_1), len(ids_student_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
