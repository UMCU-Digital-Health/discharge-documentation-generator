{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difference analysis between AI generated en final letter\n",
    "\n",
    "Analysis to see how many changes were made to the AI-draft discharge letter in comparison to the final discharge letter sent to the next treating physician."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import date\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from nltk.util import ngrams\n",
    "from rich import print as rprint\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "load_dotenv()\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWD = os.getenv(\"DB_PASSWORD\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export data to datamanager folder\n",
    "- Export database tables (request, requestdischarge, request..., encounter, generateddoc) to csv files. \n",
    "- Export data_export.parquet by running data_pipeline.py (export & processing = True, bulk generate = False).\n",
    "        Change data.to_parquet(Path(processed_data_folder / \"evaluation_data.parquet\")) to new datamanager folder. \n",
    "- Export final_discharge_letters.csv by running metavision_discharge_docs_retro.sql (if only metavision is used). Change the period start and end. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from application database export file\n",
    "data_folder = Path(\n",
    "    \"/mapr/administratielast/administratielast_datamanager/ontslagdocumentatie/PMS_1_IC_NICU\"\n",
    ")\n",
    "\n",
    "date_analysis = \"2025-07-15\"\n",
    "request_retrieve = pd.read_csv(\n",
    "    data_folder / Path(date_analysis + \"-requestretrieve.csv\")\n",
    ")\n",
    "request_generate = pd.read_csv(\n",
    "    data_folder / Path(date_analysis + \"-requestgenerate.csv\")\n",
    ")\n",
    "request = pd.read_csv(\n",
    "    data_folder / Path(date_analysis + \"-request.csv\"),\n",
    "    engine=\"pyarrow\",\n",
    "    parse_dates=[\"timestamp\"],\n",
    ")\n",
    "encounter = pd.read_csv(data_folder / Path(date_analysis + \"-encounter.csv\"))\n",
    "generateddoc = pd.read_csv(data_folder / Path(date_analysis + \"-generateddoc.csv\"))\n",
    "data = pd.read_parquet(data_folder / Path(\"data_export_pms_1.parquet\"))\n",
    "final_discharge = pd.read_csv(data_folder / \"final_discharge_letters.csv\")\n",
    "\n",
    "display(request_retrieve.head())\n",
    "display(request_generate.head())\n",
    "display(request.head())\n",
    "display(encounter.head())\n",
    "display(generateddoc.head())\n",
    "display(data.head())\n",
    "display(final_discharge.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = date(2025, 4, 1)\n",
    "END_DATE = date(2025, 7, 1)\n",
    "DEPARTMENTS = [\"IC\", \"NICU\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create generated_doc_merged\n",
    "This table is the result of a merge between the encounter, generateddoc, request_generate, and request tables. It holds all information on the generated documents combined with the generated requests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_doc_merged = (\n",
    "    pd.merge(\n",
    "        encounter,\n",
    "        generateddoc,\n",
    "        left_on=\"id\",\n",
    "        right_on=\"encounter_id\",\n",
    "        how=\"inner\",\n",
    "        suffixes=(\"_encounter\", \"_generateddoc\"),\n",
    "    )\n",
    "    .drop(columns=\"encounter_id\")\n",
    "    .rename(columns={\"id_generateddoc\": \"generated_doc_id\"})\n",
    ")\n",
    "\n",
    "\n",
    "generated_doc_merged = generated_doc_merged.join(\n",
    "    request_generate.set_index(\"id\"),\n",
    "    on=\"request_generate_id\",\n",
    "    rsuffix=\"_request_generate\",\n",
    ")\n",
    "\n",
    "generated_doc_merged = generated_doc_merged.join(\n",
    "    request.set_index(\"id\"),\n",
    "    on=\"request_id\",\n",
    "    rsuffix=\"_request\",\n",
    ")\n",
    "\n",
    "generated_doc_merged[\"timestamp\"] = pd.to_datetime(generated_doc_merged[\"timestamp\"])\n",
    "\n",
    "generated_doc_merged = generated_doc_merged[\n",
    "    (generated_doc_merged[\"timestamp\"].dt.date >= START_DATE)\n",
    "    & (generated_doc_merged[\"timestamp\"].dt.date <= END_DATE)\n",
    "]\n",
    "\n",
    "generated_doc_merged = generated_doc_merged[\n",
    "    generated_doc_merged[\"department\"].isin(DEPARTMENTS)\n",
    "    | generated_doc_merged[\"department\"].isnull()\n",
    "]\n",
    "\n",
    "display(generated_doc_merged.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create request_retrieve_merged\n",
    "This table is the result of a merge between encounter, request_retrieve, and request. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_retrieve_merged = pd.merge(\n",
    "    request_retrieve,\n",
    "    request,\n",
    "    left_on=\"request_id\",\n",
    "    right_on=\"id\",\n",
    "    how=\"inner\",\n",
    "    suffixes=(\"_request\", \"_encounter\"),\n",
    ")\n",
    "\n",
    "request_retrieve_merged = request_retrieve_merged.join(\n",
    "    encounter.set_index(\"enc_id\"),\n",
    "    on=\"request_enc_id\",\n",
    "    rsuffix=\"_encounter\",\n",
    "    how=\"outer\",\n",
    ")\n",
    "\n",
    "request_retrieve_merged[\"timestamp\"] = pd.to_datetime(\n",
    "    request_retrieve_merged[\"timestamp\"]\n",
    ")\n",
    "\n",
    "request_retrieve_merged = request_retrieve_merged[\n",
    "    (request_retrieve_merged[\"timestamp\"].dt.date >= START_DATE)\n",
    "    & (request_retrieve_merged[\"timestamp\"].dt.date <= END_DATE)\n",
    "]\n",
    "\n",
    "request_retrieve_merged = request_retrieve_merged[\n",
    "    request_retrieve_merged[\"department\"].isin(DEPARTMENTS)\n",
    "    | request_retrieve_merged[\"department\"].isnull()\n",
    "]\n",
    "\n",
    "display(request_retrieve_merged.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generated doc outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_docs_generated = generated_doc_merged[\"generated_doc_id\"].nunique()\n",
    "rprint(f\"Number of generated docs: {number_of_docs_generated}\")\n",
    "\n",
    "number_of_successful_docs = generated_doc_merged.loc[\n",
    "    generated_doc_merged[\"success_ind\"] == \"Success\"\n",
    "][\"generated_doc_id\"].nunique()\n",
    "rprint(f\"Number of successfully generated docs: {number_of_successful_docs}\")\n",
    "\n",
    "number_of_encounters = generated_doc_merged[\"enc_id\"].nunique()\n",
    "rprint(f\"Number of unique encounters: {number_of_encounters}\")\n",
    "\n",
    "\n",
    "failure_reasons = generated_doc_merged[\n",
    "    generated_doc_merged[\"success_ind\"] != \"Success\"\n",
    "][\"success_ind\"].value_counts()\n",
    "rprint(f\"Reasons for not successful generation: {failure_reasons}\")\n",
    "\n",
    "perc_generateddoc_too_long = failure_reasons.LengthError / number_of_docs_generated\n",
    "rprint(\n",
    "    \"Percentage of letters that were not generated because file was too long: \"\n",
    "    f\"{perc_generateddoc_too_long * 100:.2f} %\"\n",
    ")\n",
    "\n",
    "length_error_encounters = generated_doc_merged[\n",
    "    generated_doc_merged[\"success_ind\"] == \"LengthError\"\n",
    "][\"enc_id\"].nunique()\n",
    "rprint(f\"Number of unique encounters with length error: {length_error_encounters}\")\n",
    "\n",
    "perc_length_error_encounters = (length_error_encounters / number_of_encounters) * 100\n",
    "rprint(\n",
    "    \"Percentage of unique encounters with length error: \"\n",
    "    f\"{perc_length_error_encounters:.2f} %\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_processed_requests = generated_doc_merged[\"request_id\"].count()\n",
    "rprint(f\"Number of processed requests: {number_of_processed_requests}\")\n",
    "\n",
    "number_of_unique_processed_requests = generated_doc_merged[\"request_id\"].nunique()\n",
    "rprint(f\"Number of unique processed requests: {number_of_unique_processed_requests}\")\n",
    "\n",
    "number_of_retrieved_requests = request_retrieve_merged[\"request_id\"].nunique()\n",
    "rprint(f\"Number of retrieved requests: {number_of_retrieved_requests}\")\n",
    "\n",
    "number_of_successfully_retrieved_requests = request_retrieve_merged[\n",
    "    request_retrieve_merged[\"success_ind\"] != 0\n",
    "][\"request_id\"].nunique()\n",
    "rprint(\n",
    "    f\"Number of successfully retrieved requests: \"\n",
    "    f\"{number_of_successfully_retrieved_requests}\"\n",
    ")\n",
    "\n",
    "percentage_successfully_retrieved_requests = (\n",
    "    number_of_successfully_retrieved_requests / number_of_retrieved_requests * 100\n",
    ")\n",
    "rprint(\n",
    "    \"Percentage of successfully retrieved requests: \"\n",
    "    f\"{percentage_successfully_retrieved_requests:.2f} %\"\n",
    ")\n",
    "\n",
    "number_of_encounters_with_successfully_retrieved_requests = request_retrieve_merged[\n",
    "    request_retrieve_merged[\"success_ind\"] != 0\n",
    "][\"request_enc_id\"].nunique()\n",
    "rprint(\n",
    "    \"Number of unique encounters with successfully retrieved requests: \"\n",
    "    f\"{number_of_encounters_with_successfully_retrieved_requests}\"\n",
    ")\n",
    "\n",
    "percentage_encounters_with_successfully_retrieved_requests = (\n",
    "    number_of_encounters_with_successfully_retrieved_requests\n",
    "    / number_of_encounters\n",
    "    * 100\n",
    ")\n",
    "rprint(\n",
    "    \"Percentage of unique encounters with successfully retrieved requests: \"\n",
    "    f\"{percentage_encounters_with_successfully_retrieved_requests:.2f} %\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine generated docs with Metavision docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metavision_discharge_docs = (\n",
    "    data.loc[data[\"description\"] == \"Ontslagbrief\"]\n",
    "    .sort_values(\"date\", ascending=True)\n",
    "    .drop_duplicates(subset=\"enc_id\", keep=\"last\")\n",
    ")\n",
    "# Metavision letters use \\r\\n for newlines or double newlines and sometimes add ...\n",
    "# at the end of a sentence\n",
    "metavision_discharge_docs[\"content\"] = metavision_discharge_docs[\"content\"].str.replace(\n",
    "    \"\\r\", \"\"\n",
    ")\n",
    "metavision_discharge_docs[\"content\"] = metavision_discharge_docs[\"content\"].str.replace(\n",
    "    \"\\n\\n\\n\", \"\\n\\n\"\n",
    ")\n",
    "metavision_discharge_docs[\"content\"] = metavision_discharge_docs[\"content\"].str.replace(\n",
    "    \"...\", \"\"\n",
    ")\n",
    "\n",
    "display(metavision_discharge_docs.head())\n",
    "\n",
    "generated_doc_merged = generated_doc_merged.sort_values(\n",
    "    \"timestamp\", ascending=True\n",
    ").drop_duplicates(subset=\"enc_id\", keep=\"last\")\n",
    "\n",
    "merged_discharge_docs = generated_doc_merged.join(\n",
    "    metavision_discharge_docs.set_index(\"enc_id\"),\n",
    "    on=\"enc_id\",\n",
    "    rsuffix=\"_metavision\",\n",
    ")\n",
    "\n",
    "display(merged_discharge_docs.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print number of unique encounters in merged discharge docs\n",
    "number_of_unique_encounters_in_merged_docs = merged_discharge_docs[\"enc_id\"].nunique()\n",
    "rprint(\n",
    "    f\"Number of unique encounters in merged discharge docs: \"\n",
    "    f\"{number_of_unique_encounters_in_merged_docs}\"\n",
    ")\n",
    "\n",
    "#  Filter out rows where the document was not successfully generated\n",
    "merged_discharge_docs = merged_discharge_docs[\n",
    "    merged_discharge_docs[\"success_ind\"] == \"Success\"\n",
    "]\n",
    "\n",
    "number_of_unique_encounters_in_merged_docs = merged_discharge_docs[\"enc_id\"].nunique()\n",
    "rprint(\n",
    "    f\"Number of unique encounters with successfully generated discharge docs: \"\n",
    "    f\"{number_of_unique_encounters_in_merged_docs}\"\n",
    ")\n",
    "\n",
    "# Filter out letters where the generated document was never requested\n",
    "request_retrieve_merged_successfully = request_retrieve_merged[\n",
    "    request_retrieve_merged[\"success_ind\"] != 0\n",
    "]\n",
    "\n",
    "enc_ids_successfully_retrieved = request_retrieve_merged_successfully[\n",
    "    \"request_enc_id\"\n",
    "].unique()\n",
    "rprint(\n",
    "    f\"Number of unique encounters with successfully retrieved requests: \"\n",
    "    f\"{len(enc_ids_successfully_retrieved)}\"\n",
    ")\n",
    "\n",
    "merged_discharge_docs = merged_discharge_docs[\n",
    "    merged_discharge_docs[\"enc_id\"].isin(enc_ids_successfully_retrieved)\n",
    "]\n",
    "\n",
    "number_of_unique_encounters_in_merged_docs = merged_discharge_docs[\"enc_id\"].nunique()\n",
    "rprint(\n",
    "    \"Number of unique encounters with successfully retrieved requests in merged \"\n",
    "    f\"discharge docs: {number_of_unique_encounters_in_merged_docs}\"\n",
    ")\n",
    "\n",
    "# Filter out discharge docs with a missing description\n",
    "merged_discharge_docs = merged_discharge_docs[\n",
    "    merged_discharge_docs[\"description\"].notna()\n",
    "]\n",
    "\n",
    "rprint(\n",
    "    \"Number of unique encounters with successfully generated discharge docs and \"\n",
    "    f\"a original letter in metavision: {merged_discharge_docs['enc_id'].nunique()}\"\n",
    ")\n",
    "\n",
    "display(merged_discharge_docs.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check differences between generated and Metavision docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_common_substring(generated_letter: str, original_letter: str) -> str:\n",
    "    \"\"\"Finds the longest common substring between two strings\n",
    "    using dynamic programming.\"\"\"\n",
    "    generated_letter = generated_letter.lower()\n",
    "    original_letter = original_letter.lower()\n",
    "    m, n = len(generated_letter), len(original_letter)\n",
    "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "\n",
    "    max_length = 0\n",
    "    end_index = 0  # End index of the longest substring in generated_letter\n",
    "\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            if generated_letter[i - 1] == original_letter[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1] + 1\n",
    "                if dp[i][j] > max_length:\n",
    "                    max_length = dp[i][j]\n",
    "                    end_index = i\n",
    "\n",
    "    return generated_letter[end_index - max_length : end_index]\n",
    "\n",
    "\n",
    "longest_common_substring(\"dit is een \\ntest zin\", \"is maar een \\nTester\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_lcs(\n",
    "    df: pd.DataFrame,\n",
    "    enc_id: int,\n",
    "    content_column: str = \"content\",\n",
    "    discharge_letter_column: str = \"discharge_letter\",\n",
    ") -> None:\n",
    "    \"\"\"retrieves the row for the given encounter id and\n",
    "    highlights the longest common substring using rich\"\"\"\n",
    "    enc_row = df.loc[df[\"enc_id\"] == enc_id]\n",
    "\n",
    "    original_letter = enc_row[content_column].to_numpy()[0]\n",
    "    generated_letter = enc_row[discharge_letter_column].to_numpy()[0]\n",
    "\n",
    "    lcs = longest_common_substring(generated_letter, original_letter)\n",
    "\n",
    "    # Use rich to highlight the longest common substring in both letters\n",
    "    replace_pattern = re.compile(re.escape(lcs), re.IGNORECASE)\n",
    "    original_letter = replace_pattern.sub(\n",
    "        f\"[italic green]{lcs}[/italic green]\", original_letter\n",
    "    )\n",
    "    generated_letter = replace_pattern.sub(\n",
    "        f\"[italic green]{lcs}[/italic green]\", generated_letter\n",
    "    )\n",
    "    rprint(\"[bold yellow]Original letter[/bold yellow]\")\n",
    "    rprint(original_letter)\n",
    "    rprint(\"[bold yellow]Generated letter[/bold yellow]\")\n",
    "    rprint(generated_letter)\n",
    "\n",
    "\n",
    "highlight_lcs(merged_discharge_docs, 10705)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lcs_distance(generated_letter: str, original_letter: str) -> float:\n",
    "    \"\"\"Calculate the longest common substring distance between two strings\n",
    "\n",
    "    Score of 0 means identical texts, while a score of 1 means no common substrings.\n",
    "    \"\"\"\n",
    "    lcs = longest_common_substring(generated_letter, original_letter)\n",
    "    longest_text = max(len(generated_letter), len(original_letter))\n",
    "    return (longest_text - len(lcs)) / longest_text\n",
    "\n",
    "\n",
    "merged_discharge_docs[\"lcs_distance\"] = merged_discharge_docs.progress_apply(\n",
    "    lambda x: lcs_distance(x[\"discharge_letter\"], x[\"content\"]), axis=1\n",
    ")  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_distance(generated_letter: str, original_letter: str, n: int) -> float:\n",
    "    \"\"\"Calculate the Jaccard distance between two strings using n-grams\n",
    "\n",
    "    Score of 0 means identical texts, while a score of 1 means no common n-grams.\n",
    "    \"\"\"\n",
    "    generated_letter_words = generated_letter.lower().split()\n",
    "    original_letter_words = original_letter.lower().split()\n",
    "\n",
    "    ngrams_generated = set(ngrams(generated_letter_words, n))\n",
    "    ngrams_original = set(ngrams(original_letter_words, n))\n",
    "\n",
    "    ngrams_union = ngrams_generated.union(ngrams_original)\n",
    "    if len(ngrams_union) == 0:\n",
    "        return 0\n",
    "    ngrams_intersection = ngrams_generated.intersection(ngrams_original)\n",
    "    return 1 - len(ngrams_intersection) / len(ngrams_union)\n",
    "\n",
    "\n",
    "merged_discharge_docs[\"ngram_1\"] = merged_discharge_docs.apply(\n",
    "    lambda x: jaccard_distance(x[\"discharge_letter\"], x[\"content\"], 1), axis=1\n",
    ")\n",
    "merged_discharge_docs[\"ngram_2\"] = merged_discharge_docs.apply(\n",
    "    lambda x: jaccard_distance(x[\"discharge_letter\"], x[\"content\"], 2), axis=1\n",
    ")\n",
    "merged_discharge_docs[\"ngram_3\"] = merged_discharge_docs.apply(\n",
    "    lambda x: jaccard_distance(x[\"discharge_letter\"], x[\"content\"], 3), axis=1\n",
    ")\n",
    "merged_discharge_docs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display best matching rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_discharge_docs.sort_values(\"ngram_3\", ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "merged_discharge_docs[\"ngram_3\"].plot.hist(ax=ax, bins=20)\n",
    "ax.set_title(\"Jaccard distance between generated and original letters\")\n",
    "ax.set_xlabel(\"Jaccard distance\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_discharge_docs.sort_values(\"lcs_distance\", ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "merged_discharge_docs[\"lcs_distance\"].plot.hist(ax=ax, bins=20)\n",
    "ax.set_title(\"Longest common substring distance between generated and original letters\")\n",
    "ax.set_xlabel(\"LCS distance\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_3_groups = pd.cut(\n",
    "    merged_discharge_docs[\"ngram_3\"],\n",
    "    bins=[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 1],\n",
    ")\n",
    "ngram_3_groups.value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcs_groups = pd.cut(\n",
    "    merged_discharge_docs[\"lcs_distance\"],\n",
    "    bins=[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    ")\n",
    "lcs_groups.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect best matching letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_example(\n",
    "    df: pd.DataFrame,\n",
    "    threshold_score: float,\n",
    "    score_col: str = \"ngram_3\",\n",
    "    col1: str = \"content\",\n",
    "    col2: str = \"discharge_letter\",\n",
    ") -> None:\n",
    "    \"\"\"Find Closes example to the given threshold score\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The dataframe containing the discharge letters\n",
    "    ngram_score : float\n",
    "        The ngram score to use as a threshold\n",
    "    \"\"\"\n",
    "    sorted_df = df.loc[\n",
    "        df[score_col] > threshold_score, [\"enc_id\", score_col]\n",
    "    ].sort_values(score_col, ascending=True)\n",
    "    enc_id = sorted_df[\"enc_id\"].iat[0]\n",
    "    actual_score = sorted_df[score_col].iat[0]\n",
    "    rprint(f\"[bold]Encounter ID: {enc_id}, {score_col} score: {actual_score}[/bold]\")\n",
    "    highlight_lcs(df, enc_id, col1, col2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_closest_example(merged_discharge_docs, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_closest_example(merged_discharge_docs, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_closest_example(merged_discharge_docs, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_closest_example(merged_discharge_docs, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_closest_example(merged_discharge_docs, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_closest_example(merged_discharge_docs, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_closest_example(merged_discharge_docs, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_closest_example(merged_discharge_docs, 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check differences Metavision letter and final discharge letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_discharge_filtered = (\n",
    "    final_discharge.sort_values(\"date\", ascending=False)\n",
    "    .drop_duplicates(subset=\"enc_id\", keep=\"first\")\n",
    "    .rename(columns={\"content\": \"final_doc\"})[[\"enc_id\", \"final_doc\"]]\n",
    ")\n",
    "final_merged_docs = merged_discharge_docs.merge(\n",
    "    final_discharge_filtered, on=\"enc_id\", how=\"left\"\n",
    ")\n",
    "# Somehow some of the final letters contain floats and Nans..\n",
    "final_merged_docs = final_merged_docs.dropna(subset=[\"final_doc\"])\n",
    "final_merged_docs[\"final_doc\"] = final_merged_docs[\"final_doc\"].astype(str)\n",
    "final_merged_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_dist_final(metavision_letter: str, final_letter: str, n: int) -> float:\n",
    "    \"\"\"Updated ngram distance that only compares the intersection\n",
    "    with the metavision letters\"\"\"\n",
    "    metavision_letter_words = metavision_letter.lower().split()\n",
    "    final_letter_words = final_letter.lower().split()\n",
    "\n",
    "    ngrams_metavision = set(ngrams(metavision_letter_words, n))\n",
    "    ngrams_final = set(ngrams(final_letter_words, n))\n",
    "\n",
    "    ngrams_intersection = ngrams_metavision.intersection(ngrams_final)\n",
    "    if len(ngrams_metavision) == 0:\n",
    "        return 1\n",
    "    return 1 - len(ngrams_intersection) / len(ngrams_metavision)\n",
    "\n",
    "\n",
    "final_merged_docs[\"ngram_3_final\"] = final_merged_docs.progress_apply(\n",
    "    lambda x: ngram_dist_final(x[\"content\"], x[\"final_doc\"], 3), axis=1\n",
    ")  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "final_merged_docs[\"ngram_3_final\"].plot.hist(ax=ax, bins=20)\n",
    "ax.set_title(\"Percentage verschil in 3-grams tussen metavision en laatste brief\")\n",
    "ax.set_xlabel(\"Percentage verschil\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ngram_bins = pd.cut(\n",
    "    final_merged_docs[\"ngram_3_final\"],\n",
    "    bins=[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    ")\n",
    "final_ngram_bins.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_closest_example(final_merged_docs, 0.4, \"ngram_3_final\", \"content\", \"final_doc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "discharge-docs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
