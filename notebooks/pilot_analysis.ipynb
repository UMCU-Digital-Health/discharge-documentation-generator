{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difference analysis between AI generated en final letter\n",
    "\n",
    "Analysis to see how many changes were made to the AI-draft discharge letter in comparison to the final discharge letter sent to the next treating physician."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from nltk.util import ngrams\n",
    "from rich import print as rprint\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "load_dotenv()\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWD = os.getenv(\"DB_PASSWORD\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from application database export file\n",
    "data_folder = (\n",
    "    Path(\"/mapr/administratielast/administratielast_datamanager/ontslagdocumentatie/\")\n",
    "    / \"Pilot Evaluatie IC NICU\"\n",
    ")\n",
    "\n",
    "date = \"2025-03-05\"\n",
    "request = pd.read_csv(data_folder / Path(date + \"-apirequest.csv\"))\n",
    "encounter = pd.read_csv(data_folder / Path(date + \"-apiencounter.csv\"))\n",
    "generateddoc = pd.read_csv(data_folder / Path(date + \"-apigenerateddoc.csv\"))\n",
    "feedback = pd.read_csv(data_folder / Path(date + \"-apifeedback.csv\"))\n",
    "data = pd.read_parquet(data_folder / Path(\"data_export_pilot.parquet\"))\n",
    "final_discharge = pd.read_csv(data_folder / \"pilot_final_discharge_letters.csv\")\n",
    "\n",
    "display(request.head())\n",
    "display(encounter.head())\n",
    "display(generateddoc.head())\n",
    "display(feedback.head())\n",
    "display(data.head())\n",
    "display(final_discharge.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PILOT_START_DATE = \"2024-10-15\"\n",
    "PILOT_END_DATE = \"2024-12-10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numbers surrounding the pilot\n",
    "\n",
    "num_encounters = generateddoc[\n",
    "    (generateddoc[\"generation_date\"] >= PILOT_START_DATE)\n",
    "    & (generateddoc[\"generation_date\"] <= PILOT_END_DATE)\n",
    "][\"encounter_id\"].nunique()\n",
    "print(f\"Number of encounters: {num_encounters}\")\n",
    "\n",
    "num_generated_docs = generateddoc[\n",
    "    (generateddoc[\"generation_date\"] >= PILOT_START_DATE)\n",
    "    & (generateddoc[\"generation_date\"] <= PILOT_END_DATE)\n",
    "].shape[0]\n",
    "print(f\"Number of generated documents: {num_generated_docs}\")\n",
    "\n",
    "num_successful_generated_docs = generateddoc[\n",
    "    (generateddoc[\"generation_date\"] >= PILOT_START_DATE)\n",
    "    & (generateddoc[\"generation_date\"] <= PILOT_END_DATE)\n",
    "    & (generateddoc[\"success\"] == \"Success\")\n",
    "].shape[0]\n",
    "print(f\"Number of successful generated documents: {num_successful_generated_docs}\")\n",
    "\n",
    "failure_reasons = generateddoc[\n",
    "    (generateddoc[\"generation_date\"] >= PILOT_START_DATE)\n",
    "    & (generateddoc[\"generation_date\"] <= PILOT_END_DATE)\n",
    "    & (generateddoc[\"success\"] != \"Success\")\n",
    "][\"success\"].value_counts()\n",
    "print(f\"Reasons for not successful generation: {failure_reasons}\")\n",
    "\n",
    "perc_enc_too_long = failure_reasons.LengthError / num_generated_docs\n",
    "print(\n",
    "    \"Percentage of letters that were not generated because file was too long: \"\n",
    "    f\"{perc_enc_too_long * 100} (most at NICU)\"\n",
    ")\n",
    "\n",
    "length_error_encounters = generateddoc[\n",
    "    (generateddoc[\"generation_date\"] >= PILOT_START_DATE)\n",
    "    & (generateddoc[\"generation_date\"] <= PILOT_END_DATE)\n",
    "    & (generateddoc[\"success\"] == \"LengthError\")\n",
    "][\"encounter_id\"]\n",
    "print(f\"Number of encounters with too long files: {length_error_encounters.nunique()}\")\n",
    "\n",
    "\n",
    "print(\n",
    "    \"Percentage of encounters with patient file ending up too long: \"\n",
    "    f\"{num_encounters * 100}\"\n",
    ")\n",
    "\n",
    "request[[\"encounter_id\", \"retrieved_generated_doc_id\"]] = (\n",
    "    request.loc[request[\"endpoint\"] == \"/retrieve_discharge_doc\", \"logging_number\"]\n",
    "    .str.extract(r\"^(\\d+)_([\\d]+)$\")\n",
    "    .astype(\"Int64\")\n",
    ")\n",
    "num_retrieve_requests = request.loc[\n",
    "    (request[\"timestamp\"] >= PILOT_START_DATE)\n",
    "    & (request[\"timestamp\"] <= PILOT_END_DATE)\n",
    "].shape[0]\n",
    "print(f\"Number of retrieve requests: {num_retrieve_requests}\")\n",
    "num_retrieved_docs = request.loc[\n",
    "    (request[\"timestamp\"] >= PILOT_START_DATE)\n",
    "    & (request[\"timestamp\"] <= PILOT_END_DATE),\n",
    "    \"retrieved_generated_doc_id\",\n",
    "].count()\n",
    "num_unique_retrieved_docs = request.loc[\n",
    "    (request[\"timestamp\"] >= PILOT_START_DATE)\n",
    "    & (request[\"timestamp\"] <= PILOT_END_DATE),\n",
    "    \"retrieved_generated_doc_id\",\n",
    "].nunique()\n",
    "num_encounters_with_retrieved_docs = request.loc[\n",
    "    (request[\"timestamp\"] >= PILOT_START_DATE)\n",
    "    & (request[\"timestamp\"] <= PILOT_END_DATE),\n",
    "    \"encounter_id\",\n",
    "].nunique()\n",
    "\n",
    "print(f\"Number of times document successfully retrieved: {num_retrieved_docs}\")\n",
    "print(f\"Number of unique documents successfully retrieved: {num_unique_retrieved_docs}\")\n",
    "print(\n",
    "    \"number of encounters with retrieved documents: \"\n",
    "    f\"{num_encounters_with_retrieved_docs}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine generated docs with Metavision docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metavision_discharge_docs = (\n",
    "    data.loc[data[\"description\"] == \"Ontslagbrief\"]\n",
    "    .sort_values(\"date\", ascending=True)\n",
    "    .drop_duplicates(subset=\"enc_id\", keep=\"last\")\n",
    ")\n",
    "# Metavision letters use \\r\\n for newlines or double newlines and sometimes add ...\n",
    "# at the end of a sentence\n",
    "metavision_discharge_docs[\"content\"] = metavision_discharge_docs[\"content\"].str.replace(\n",
    "    \"\\r\", \"\"\n",
    ")\n",
    "metavision_discharge_docs[\"content\"] = metavision_discharge_docs[\"content\"].str.replace(\n",
    "    \"\\n\\n\\n\", \"\\n\\n\"\n",
    ")\n",
    "metavision_discharge_docs[\"content\"] = metavision_discharge_docs[\"content\"].str.replace(\n",
    "    \"...\", \"\"\n",
    ")\n",
    "\n",
    "generated_discharge_docs = (\n",
    "    generateddoc.loc[\n",
    "        (generateddoc[\"generation_date\"] >= PILOT_START_DATE)\n",
    "        & (generateddoc[\"generation_date\"] <= PILOT_END_DATE)\n",
    "    ]\n",
    "    .sort_values(\"generation_date\", ascending=True)\n",
    "    .drop_duplicates(subset=\"encounter_id\", keep=\"last\")\n",
    "    .merge(encounter, left_on=\"encounter_id\", right_on=\"id\")\n",
    ")\n",
    "\n",
    "merged_discharge_docs = metavision_discharge_docs.merge(\n",
    "    generated_discharge_docs, left_on=\"enc_id\", right_on=\"encounter_hix_id\"\n",
    ")\n",
    "merged_discharge_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also filter out discharge letters where the generated document was never requested\n",
    "retrieve_requests = request.loc[\n",
    "    (request[\"endpoint\"] == \"/retrieve_discharge_doc\")\n",
    "    & (request[\"logging_number\"] != \"0\")\n",
    "    & (request[\"timestamp\"] >= PILOT_START_DATE)\n",
    "    & (request[\"timestamp\"] <= PILOT_END_DATE)\n",
    "].copy()\n",
    "retrieve_requests[\"enc_id\"] = retrieve_requests[\"logging_number\"].str.extract(\n",
    "    r\"(\\d+)_\\d+\"\n",
    ")\n",
    "retrieve_requests = retrieve_requests[retrieve_requests[\"enc_id\"].notnull()]\n",
    "retrieve_requests[\"enc_id\"] = retrieve_requests[\"enc_id\"].astype(int)\n",
    "retrieved_encs = retrieve_requests.merge(encounter, left_on=\"enc_id\", right_on=\"id\")[\n",
    "    \"encounter_hix_id\"\n",
    "].unique()\n",
    "\n",
    "percentage_retrieved = (\n",
    "    merged_discharge_docs[merged_discharge_docs[\"enc_id\"].isin(retrieved_encs)].shape[0]\n",
    "    / merged_discharge_docs.shape[0]\n",
    ")\n",
    "print(\n",
    "    f\"Percentage of discharge letters that were retrieved: {percentage_retrieved:.2%}\"\n",
    ")\n",
    "\n",
    "merged_discharge_docs = merged_discharge_docs[\n",
    "    merged_discharge_docs[\"enc_id\"].isin(retrieved_encs)\n",
    "].copy()\n",
    "merged_discharge_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check differences between generated and Metavision docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_common_substring(generated_letter: str, original_letter: str) -> str:\n",
    "    \"\"\"Finds the longest common substring between two strings\n",
    "    using dynamic programming.\"\"\"\n",
    "    generated_letter = generated_letter.lower()\n",
    "    original_letter = original_letter.lower()\n",
    "    m, n = len(generated_letter), len(original_letter)\n",
    "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "\n",
    "    max_length = 0\n",
    "    end_index = 0  # End index of the longest substring in generated_letter\n",
    "\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            if generated_letter[i - 1] == original_letter[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1] + 1\n",
    "                if dp[i][j] > max_length:\n",
    "                    max_length = dp[i][j]\n",
    "                    end_index = i\n",
    "\n",
    "    return generated_letter[end_index - max_length : end_index]\n",
    "\n",
    "\n",
    "longest_common_substring(\"dit is een \\ntest zin\", \"is maar een \\nTester\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_lcs(\n",
    "    df: pd.DataFrame, enc_id: int, col1: str = \"content\", col2: str = \"discharge_letter\"\n",
    ") -> None:\n",
    "    \"\"\"retrieves the row for the given encounter id and\n",
    "    highlights the longest common substring using rich\"\"\"\n",
    "    enc_row = df.loc[df[\"enc_id\"] == enc_id]\n",
    "\n",
    "    original_letter = enc_row[col1].to_numpy()[0]\n",
    "    generated_letter = enc_row[col2].to_numpy()[0]\n",
    "\n",
    "    lcs = longest_common_substring(generated_letter, original_letter)\n",
    "\n",
    "    # Use rich to highlight the longest common substring in both letters\n",
    "    replace_pattern = re.compile(re.escape(lcs), re.IGNORECASE)\n",
    "    original_letter = replace_pattern.sub(\n",
    "        f\"[italic green]{lcs}[/italic green]\", original_letter\n",
    "    )\n",
    "    generated_letter = replace_pattern.sub(\n",
    "        f\"[italic green]{lcs}[/italic green]\", generated_letter\n",
    "    )\n",
    "    rprint(\"[bold yellow]Original letter[/bold yellow]\")\n",
    "    rprint(original_letter)\n",
    "    rprint(\"[bold yellow]Generated letter[/bold yellow]\")\n",
    "    rprint(generated_letter)\n",
    "\n",
    "\n",
    "highlight_lcs(merged_discharge_docs, 8791)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lcs_distance(generated_letter: str, original_letter: str) -> float:\n",
    "    \"\"\"Calculate the longest common substring distance between two strings\n",
    "\n",
    "    Score of 0 means identical texts, while a score of 1 means no common substrings.\n",
    "    \"\"\"\n",
    "    lcs = longest_common_substring(generated_letter, original_letter)\n",
    "    longest_text = max(len(generated_letter), len(original_letter))\n",
    "    return (longest_text - len(lcs)) / longest_text\n",
    "\n",
    "\n",
    "merged_discharge_docs[\"lcs_distance\"] = merged_discharge_docs.progress_apply(\n",
    "    lambda x: lcs_distance(x[\"discharge_letter\"], x[\"content\"]), axis=1\n",
    ")  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_distance(generated_letter: str, original_letter: str, n: int) -> float:\n",
    "    \"\"\"Calculate the Jaccard distance between two strings using n-grams\n",
    "\n",
    "    Score of 0 means identical texts, while a score of 1 means no common n-grams.\n",
    "    \"\"\"\n",
    "    generated_letter_words = generated_letter.lower().split()\n",
    "    original_letter_words = original_letter.lower().split()\n",
    "\n",
    "    ngrams_generated = set(ngrams(generated_letter_words, n))\n",
    "    ngrams_original = set(ngrams(original_letter_words, n))\n",
    "\n",
    "    ngrams_union = ngrams_generated.union(ngrams_original)\n",
    "    if len(ngrams_union) == 0:\n",
    "        return 0\n",
    "    ngrams_intersection = ngrams_generated.intersection(ngrams_original)\n",
    "    return 1 - len(ngrams_intersection) / len(ngrams_union)\n",
    "\n",
    "\n",
    "merged_discharge_docs[\"ngram_1\"] = merged_discharge_docs.apply(\n",
    "    lambda x: jaccard_distance(x[\"discharge_letter\"], x[\"content\"], 1), axis=1\n",
    ")\n",
    "merged_discharge_docs[\"ngram_2\"] = merged_discharge_docs.apply(\n",
    "    lambda x: jaccard_distance(x[\"discharge_letter\"], x[\"content\"], 2), axis=1\n",
    ")\n",
    "merged_discharge_docs[\"ngram_3\"] = merged_discharge_docs.apply(\n",
    "    lambda x: jaccard_distance(x[\"discharge_letter\"], x[\"content\"], 3), axis=1\n",
    ")\n",
    "merged_discharge_docs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display best matching rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_discharge_docs.sort_values(\"ngram_3\", ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "merged_discharge_docs[\"ngram_3\"].plot.hist(ax=ax, bins=20)\n",
    "ax.set_title(\"Jaccard distance between generated and original letters\")\n",
    "ax.set_xlabel(\"Jaccard distance\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_discharge_docs.sort_values(\"lcs_distance\", ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "merged_discharge_docs[\"lcs_distance\"].plot.hist(ax=ax, bins=20)\n",
    "ax.set_title(\"Longest common substring distance between generated and original letters\")\n",
    "ax.set_xlabel(\"LCS distance\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_3_groups = pd.cut(\n",
    "    merged_discharge_docs[\"ngram_3\"],\n",
    "    bins=[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 1],\n",
    ")\n",
    "ngram_3_groups.value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcs_groups = pd.cut(\n",
    "    merged_discharge_docs[\"lcs_distance\"],\n",
    "    bins=[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    ")\n",
    "lcs_groups.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect best matching letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_example(\n",
    "    df: pd.DataFrame,\n",
    "    threshold_score: float,\n",
    "    score_col: str = \"ngram_3\",\n",
    "    col1: str = \"content\",\n",
    "    col2: str = \"discharge_letter\",\n",
    ") -> None:\n",
    "    \"\"\"Find Closes example to the given threshold score\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The dataframe containing the discharge letters\n",
    "    ngram_score : float\n",
    "        The ngram score to use as a threshold\n",
    "    \"\"\"\n",
    "    sorted_df = df.loc[\n",
    "        df[score_col] > threshold_score, [\"enc_id\", score_col]\n",
    "    ].sort_values(score_col, ascending=True)\n",
    "    enc_id = sorted_df[\"enc_id\"].iat[0]\n",
    "    actual_score = sorted_df[score_col].iat[0]\n",
    "    rprint(f\"[bold]Encounter ID: {enc_id}, {score_col} score: {actual_score}[/bold]\")\n",
    "    highlight_lcs(df, enc_id, col1, col2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_closest_example(merged_discharge_docs, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_closest_example(merged_discharge_docs, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_closest_example(merged_discharge_docs, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_closest_example(merged_discharge_docs, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_closest_example(merged_discharge_docs, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_closest_example(merged_discharge_docs, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_closest_example(merged_discharge_docs, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_closest_example(merged_discharge_docs, 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check differences Metavision letter and final discharge letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_discharge_filtered = (\n",
    "    final_discharge.sort_values(\"date\", ascending=False)\n",
    "    .drop_duplicates(subset=\"enc_id\", keep=\"first\")\n",
    "    .rename(columns={\"content\": \"final_doc\"})[[\"enc_id\", \"final_doc\"]]\n",
    ")\n",
    "final_merged_docs = merged_discharge_docs.merge(\n",
    "    final_discharge_filtered, on=\"enc_id\", how=\"left\"\n",
    ")\n",
    "# Somehow some of the final letters contain floats and Nans..\n",
    "final_merged_docs = final_merged_docs.dropna(subset=[\"final_doc\"])\n",
    "final_merged_docs[\"final_doc\"] = final_merged_docs[\"final_doc\"].astype(str)\n",
    "final_merged_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_dist_final(metavision_letter: str, final_letter: str, n: int) -> float:\n",
    "    \"\"\"Updated ngram distance that only compares the intersection\n",
    "    with the metavision letters\"\"\"\n",
    "    metavision_letter_words = metavision_letter.lower().split()\n",
    "    final_letter_words = final_letter.lower().split()\n",
    "\n",
    "    ngrams_metavision = set(ngrams(metavision_letter_words, n))\n",
    "    ngrams_final = set(ngrams(final_letter_words, n))\n",
    "\n",
    "    ngrams_intersection = ngrams_metavision.intersection(ngrams_final)\n",
    "    if len(ngrams_metavision) == 0:\n",
    "        return 1\n",
    "    return 1 - len(ngrams_intersection) / len(ngrams_metavision)\n",
    "\n",
    "\n",
    "final_merged_docs[\"ngram_3_final\"] = final_merged_docs.progress_apply(\n",
    "    lambda x: ngram_dist_final(x[\"content\"], x[\"final_doc\"], 3), axis=1\n",
    ")  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "final_merged_docs[\"ngram_3_final\"].plot.hist(ax=ax, bins=20)\n",
    "ax.set_title(\"Percentage verschil in 3-grams tussen metavision en laatste brief\")\n",
    "ax.set_xlabel(\"Percentage verschil\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ngram_bins = pd.cut(\n",
    "    final_merged_docs[\"ngram_3_final\"],\n",
    "    bins=[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    ")\n",
    "final_ngram_bins.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_closest_example(final_merged_docs, 0.4, \"ngram_3_final\", \"content\", \"final_doc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
