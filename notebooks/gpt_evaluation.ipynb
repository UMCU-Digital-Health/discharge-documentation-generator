{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT Evaluation\n",
    "\n",
    "This notebook attempts to evaluate the performance of a prompt using GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import openai\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from discharge_docs.processing.processing import (\n",
    "    get_patient_file,\n",
    "    get_splitted_discharge_docs_NICU,\n",
    "    load_and_process_data_metavision,\n",
    ")\n",
    "from discharge_docs.prompt import load_prompts\n",
    "\n",
    "# Enables automatic reloading of (locally installed) packages\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise openAI API\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2024-02-01\"  # this may change in the future\n",
    "\n",
    "deployment_name = \"aiva-gpt\"\n",
    "\n",
    "os.environ[\"TIKTOKEN_CACHE_DIR\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get prompts\n",
    "user_prompt, system_prompt = load_pompts()\n",
    "\n",
    "# print(user_prompt   )\n",
    "\n",
    "# print(system_prompt )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get data\n",
    "\n",
    "# data = load_and_process_data_metavision()\n",
    "# enc_ids_outside_limit = []\n",
    "# size_outside_limit = []\n",
    "# enc_ids_within_limit = []\n",
    "# size_within_limit = []\n",
    "# for enc_id in data.enc_id.unique():\n",
    "#     # enc_id = 6\n",
    "#     patient_data_string, patient_data_df = get_patient_file(enc_id, data)\n",
    "#     # print(patient_data)\n",
    "#     # check the length of the patient data\n",
    "#     encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "#     # print(f\"The number of tokens in the data: {len(encoding.encode(patient_data_string))}\")\n",
    "#     # print(f\"The length of stay is: {np.mean(patient_data_df['length_of_stay'])}\")\n",
    "#     if len(encoding.encode(patient_data_string))<16000:\n",
    "#         enc_ids_within_limit.append(enc_id)\n",
    "#         size_within_limit.append(len(encoding.encode(patient_data_string)))\n",
    "#     else:\n",
    "#         enc_ids_outside_limit.append(enc_id)\n",
    "#         size_outside_limit.append(len(encoding.encode(patient_data_string)))\n",
    "# print(f\"The number of patients within the limit is: {len(enc_ids_within_limit)}\") # 176\n",
    "# print(enc_ids_within_limit)\n",
    "\"\"\"[20, 38, 39, 42, 48, 46, 55, 63, 67, 69, 68, 71, 75, 83, 91, 92, 93, 95, 99, 110, \n",
    "107, 111, 115, 116, 119, 120, 121, 126, 128, 129, 133, 138, 150, 149, 152, 165, 167, \n",
    "171, 168, 169, 175, 185, 187, 193, 200, 202, 211, 216, 217, 219, 223, 227, 228, 231, \n",
    "234, 235, 241, 243, 264, 273, 278, 279, 284, 286, 288, 292, 306, 304, 305, 310, 309,\n",
    " 317, 319, 324, 327, 326, 336, 338, 341, 343, 345, 354, 355, 357, 364, 363, 370, 374, \n",
    " 377, 381, 384, 396, 404, 405, 408, 413, 417, 420, 422, 423, 424, 425, 428, 430, 431, \n",
    " 437, 443, 439, 442, 458, 454, 463, 465, 475, 477, 488, 482, 491, 487, 490, 494, 499, \n",
    " 498, 497, 501, 510, 512, 518, 519, 522, 524, 530, 539, 540, 547, 544, 554, 557, 571, \n",
    " 569, 577, 583, 584, 591, 601, 609, 610, 613, 614, 615, 616, 624, 621, 631, 639, 648, \n",
    " 651, 662, 671, 677, 680, 682, 685, 690, 695, 697, 700, 703, 716, 714, 715, 723, 724,\n",
    "   725, 729, 730]\n",
    "\"\"\"\n",
    "# print(f\"The number of patients outside the limit is: {len(enc_ids_outside_limit)}\") # 143\n",
    "# gepseudonimiseerd & af: (subset)\n",
    "NICU = [20, 107, 116, 129, 150]\n",
    "IC = [48, 55, 63, 67, 69, 68, 71]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "data = load_and_process_data_metavision()\n",
    "\n",
    "\n",
    "enc_id = 20\n",
    "patient_data_string, patient_data_df = get_patient_file(enc_id, data)\n",
    "discharge_letter_split_df = get_splitted_discharge_docs_NICU(enc_id, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate discharge docs through GPT\n",
    "GPT_returned = get_chatgpt_output_beloop(\n",
    "    patient_data_string,\n",
    "    engine=deployment_name,\n",
    "    user_prompt=user_prompt,\n",
    "    system_prompt=system_prompt,\n",
    "    temperature=0,\n",
    ")\n",
    "GPT_returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_output = get_category_output(GPT_returned, \"Neurologie\")\n",
    "EPD_output = discharge_letter_split_df[\n",
    "    discharge_letter_split_df[\"category\"] == \"Neurologie\"\n",
    "][\"text\"].values[0]\n",
    "\n",
    "print(f\"The GPT output is: {GPT_output}\")\n",
    "print(f\"The EPD output is: {EPD_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the performance:\n",
    "\n",
    "evaluatie_prompt = load_evaluatie_prompt()\n",
    "\n",
    "n_runs = 10\n",
    "for i in range(n_runs):\n",
    "    print(f\"Run {i+1}\")\n",
    "\n",
    "    eval = compare_GPT_output_with_EPD_output(\n",
    "        GPT_output, EPD_output, evaluatie_prompt, engine=deployment_name, temperature=0\n",
    "    )\n",
    "    print(eval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiva_ontslag_laura",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
