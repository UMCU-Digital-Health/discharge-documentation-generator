{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT Evaluation\n",
    "\n",
    "This notebook attempts to evaluate the performance of a prompt using GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "from discharge_docs.processing.processing import (\n",
    "    get_patient_discharge_docs,\n",
    "    get_patient_file,\n",
    ")\n",
    "from discharge_docs.prompts.prompt import (\n",
    "    load_evaluatie_prompt,\n",
    "    load_prompts,\n",
    "    load_template_prompt,\n",
    ")\n",
    "from discharge_docs.prompts.prompt_builder import PromptBuilder\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "\n",
    "# Enables automatic reloading of (locally installed) packages\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise Azure\n",
    "load_dotenv()\n",
    "\n",
    "deployment_name = \"aiva-gpt\"\n",
    "TEMPERATURE = 0.2\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_version=\"2024-02-01\",\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\", \"\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df_metavision = pd.read_parquet(\n",
    "    Path(current_dir).parent / \"data\" / \"processed\" / \"metavision_new_data.parquet\"\n",
    ")\n",
    "\n",
    "patient_1_NICU = df_metavision[df_metavision[\"enc_id\"] == 107]\n",
    "patient_2_NICU = df_metavision[df_metavision[\"enc_id\"] == 20]\n",
    "patient_3_NICU = df_metavision[df_metavision[\"enc_id\"] == 150]\n",
    "\n",
    "patient_1_IC = df_metavision[df_metavision[\"enc_id\"] == 48]\n",
    "patient_2_IC = df_metavision[df_metavision[\"enc_id\"] == 55]\n",
    "patient_3_IC = df_metavision[df_metavision[\"enc_id\"] == 63]\n",
    "\n",
    "df_HIX = pd.read_parquet(\n",
    "    Path(current_dir).parent / \"data\" / \"processed\" / \"HiX_data.parquet\"\n",
    ")\n",
    "patient_1_CAR = df_HIX[df_HIX[\"enc_id\"] == 1012]\n",
    "patient_2_CAR = df_HIX[df_HIX[\"enc_id\"] == 1010]\n",
    "patient_3_CAR = df_HIX[df_HIX[\"enc_id\"] == 1062]\n",
    "\n",
    "patient_1_PSY = df_HIX[df_HIX[\"enc_id\"] == 1142]\n",
    "\n",
    "patient_1_demo = pd.read_csv(\n",
    "    Path(current_dir).parent / \"data\" / \"processed\" / \"DEMO_patient_1.csv\", sep=\";\"\n",
    ")\n",
    "patient_1_demo[\"date\"] = pd.to_datetime(patient_1_demo[\"date\"])\n",
    "\n",
    "data_dict = {\n",
    "    \"patient_1_nicu\": patient_1_NICU,\n",
    "    \"patient_2_nicu\": patient_2_NICU,\n",
    "    \"patient_3_nicu\": patient_3_NICU,\n",
    "    \"patient_1_ic\": patient_1_IC,\n",
    "    \"patient_2_ic\": patient_2_IC,\n",
    "    \"patient_3_ic\": patient_3_IC,\n",
    "    \"patient_1_car\": patient_1_CAR,\n",
    "    \"patient_2_car\": patient_2_CAR,\n",
    "    \"patient_3_car\": patient_3_CAR,\n",
    "    \"patient_1_psy\": patient_1_PSY,\n",
    "    \"patient_1_demo\": patient_1_demo,\n",
    "}\n",
    "\n",
    "# load prompts\n",
    "user_prompt, system_prompt = load_prompts()\n",
    "template_prompt_NICU = load_template_prompt(\"NICU\")\n",
    "template_prompt_IC = load_template_prompt(\"IC\")\n",
    "template_prompt_CAR = load_template_prompt(\"CAR\")\n",
    "template_prompt_PSY = load_template_prompt(\"PSY\")\n",
    "template_prompt_dict = {\n",
    "    \"nicu\": template_prompt_NICU,\n",
    "    \"ic\": template_prompt_IC,\n",
    "    \"car\": template_prompt_CAR,\n",
    "    \"psy\": template_prompt_PSY,\n",
    "    \"demo\": template_prompt_NICU,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_dict[\"patient_1_ic\"]\n",
    "patient_file_string, _ = get_patient_file(df=data)\n",
    "template_prompt = template_prompt_dict[\"ic\"]\n",
    "prompt_builder = PromptBuilder(\n",
    "    temperature=TEMPERATURE, deployment_name=deployment_name, client=client\n",
    ")\n",
    "\n",
    "generated_doc = prompt_builder.generate_discharge_doc(\n",
    "    patient_file=patient_file_string,\n",
    "    system_prompt=system_prompt,\n",
    "    user_prompt=user_prompt,\n",
    "    template_prompt=template_prompt,\n",
    ")\n",
    "\n",
    "GPT_letter = [f\"{x['Categorie']}: {x['Beloop tijdens opname']}\" for x in generated_doc]\n",
    "GPT_letter = \"\\n\\n\".join(GPT_letter)\n",
    "print(GPT_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OG letter\n",
    "OG_letter = get_patient_discharge_docs(df=data).values[0]\n",
    "print(OG_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_GPT_output_with_EPD_output(\n",
    "    GPT_output, EPD_output, evaluatie_prompt, engine, temperature\n",
    "):\n",
    "    messages = [\n",
    "        # {\n",
    "        #     \"role\": \"system\",\n",
    "        #     \"content\": evaluatie_system_prompt,\n",
    "        # },\n",
    "        {\"role\": \"user\", \"content\": evaluatie_prompt},\n",
    "        {\"role\": \"user\", \"content\": \"Samenvatting A: \" + EPD_output},  # samenvatting A\n",
    "        {\"role\": \"user\", \"content\": \"Samenvatting B: \" + GPT_output},  # samenvatting B\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=engine,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    reply = json.loads(\n",
    "        re.sub(\n",
    "            \"```(json)?\",\n",
    "            \"\",\n",
    "            response.model_dump()[\"choices\"][0][\"message\"][\"content\"],\n",
    "        )\n",
    "    )\n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the performance:\n",
    "\n",
    "evaluatie_prompt = load_evaluatie_prompt()\n",
    "print(evaluatie_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_output = {\n",
    "    \"Semantische Similariteit Score\": [],\n",
    "    \"Volledigheid Percentage van EPD brief\": [],\n",
    "    \"Volledigheid Percentage van GPT brief\": [],\n",
    "    \"Overlap Percentage\": [],\n",
    "}\n",
    "\n",
    "n_runs = 20\n",
    "for _i in range(n_runs):\n",
    "    eval = compare_GPT_output_with_EPD_output(\n",
    "        GPT_letter, OG_letter, evaluatie_prompt, engine=deployment_name, temperature=0\n",
    "    )\n",
    "    eval_output[\"Semantische Similariteit Score\"].append(\n",
    "        eval[\"Semantische Similariteit Score\"]\n",
    "    )\n",
    "    eval_output[\"Volledigheid Percentage van EPD brief\"].append(\n",
    "        eval[\"Volledigheid Percentage van A\"]\n",
    "    )\n",
    "    eval_output[\"Volledigheid Percentage van GPT brief\"].append(\n",
    "        eval[\"Volledigheid Percentage van B\"]\n",
    "    )\n",
    "    eval_output[\"Overlap Percentage\"].append(eval[\"Overlap Percentage\"])\n",
    "\n",
    "print(eval_output)\n",
    "# take averages over eval_output\n",
    "print(\"Average scores:\")\n",
    "\n",
    "average_eval_output = {\n",
    "    key: np.mean(value) for key, value in eval_output.items()\n",
    "}\n",
    "print(average_eval_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get data\n",
    "\n",
    "# data = load_and_process_data_metavision()\n",
    "# enc_ids_outside_limit = []\n",
    "# size_outside_limit = []\n",
    "# enc_ids_within_limit = []\n",
    "# size_within_limit = []\n",
    "# for enc_id in data.enc_id.unique():\n",
    "#     # enc_id = 6\n",
    "#     patient_data_string, patient_data_df = get_patient_file(enc_id, data)\n",
    "#     # print(patient_data)\n",
    "#     # check the length of the patient data\n",
    "#     encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "#     # print(f\"The number of tokens in the data: {len(encoding.encode(patient_data_string))}\")\n",
    "#     # print(f\"The length of stay is: {np.mean(patient_data_df['length_of_stay'])}\")\n",
    "#     if len(encoding.encode(patient_data_string))<16000:\n",
    "#         enc_ids_within_limit.append(enc_id)\n",
    "#         size_within_limit.append(len(encoding.encode(patient_data_string)))\n",
    "#     else:\n",
    "#         enc_ids_outside_limit.append(enc_id)\n",
    "#         size_outside_limit.append(len(encoding.encode(patient_data_string)))\n",
    "# print(f\"The number of patients within the limit is: {len(enc_ids_within_limit)}\") # 176\n",
    "# print(enc_ids_within_limit)\n",
    "\"\"\"[20, 38, 39, 42, 48, 46, 55, 63, 67, 69, 68, 71, 75, 83, 91, 92, 93, 95, 99, 110, \n",
    "107, 111, 115, 116, 119, 120, 121, 126, 128, 129, 133, 138, 150, 149, 152, 165, 167, \n",
    "171, 168, 169, 175, 185, 187, 193, 200, 202, 211, 216, 217, 219, 223, 227, 228, 231, \n",
    "234, 235, 241, 243, 264, 273, 278, 279, 284, 286, 288, 292, 306, 304, 305, 310, 309,\n",
    " 317, 319, 324, 327, 326, 336, 338, 341, 343, 345, 354, 355, 357, 364, 363, 370, 374, \n",
    " 377, 381, 384, 396, 404, 405, 408, 413, 417, 420, 422, 423, 424, 425, 428, 430, 431, \n",
    " 437, 443, 439, 442, 458, 454, 463, 465, 475, 477, 488, 482, 491, 487, 490, 494, 499, \n",
    " 498, 497, 501, 510, 512, 518, 519, 522, 524, 530, 539, 540, 547, 544, 554, 557, 571, \n",
    " 569, 577, 583, 584, 591, 601, 609, 610, 613, 614, 615, 616, 624, 621, 631, 639, 648, \n",
    " 651, 662, 671, 677, 680, 682, 685, 690, 695, 697, 700, 703, 716, 714, 715, 723, 724,\n",
    "   725, 729, 730]\n",
    "\"\"\"\n",
    "# print(f\"The number of patients outside the limit is: {len(enc_ids_outside_limit)}\") # 143\n",
    "# gepseudonimiseerd & af: (subset)\n",
    "NICU = [20, 107, 116, 129, 150]\n",
    "IC = [48, 55, 63, 67, 69, 68, 71]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiva_ontslag_laura",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
