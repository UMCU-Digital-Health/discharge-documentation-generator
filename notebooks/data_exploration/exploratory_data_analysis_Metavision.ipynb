{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory analysis of Metavision data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "\n",
    "os.environ[\"TIKTOKEN_CACHE_DIR\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_parquet(\"../data/raw/pseudonomised_metavision_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    if column not in [\"period_start\", \"period_end\"]:\n",
    "        unique_values = df[column].unique()\n",
    "        num_unique_values = len(unique_values)\n",
    "        print(f\"Column: {column}\")\n",
    "        print(f\"Unique Values: {unique_values}\")\n",
    "        print(f\"Number of Unique Values: {num_unique_values}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROCESSING: rename columns\n",
    "df = df.rename(columns={\"location_Location_value_original\": \"department\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verdeling patieten over de afdelingen\n",
    "print(\"Totaal aantal datapunten:\")\n",
    "print(df[\"department\"].value_counts())\n",
    "print(\"Aantal patienten:\")\n",
    "df.groupby(\"department\")[\"pseudo_id\"].nunique().plot(kind=\"pie\", autopct=\"%d\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peusdo_id en enc_id vergelijking\n",
    "enc_id_pseudo_id_count = df.groupby(\"enc_id\")[\"pseudo_id\"].nunique()\n",
    "print(enc_id_pseudo_id_count.eq(1).all())\n",
    "print(\"so all encounters have a specific patient\")\n",
    "pseudo_id_enc_id_count = df.groupby(\"pseudo_id\")[\"enc_id\"].nunique()\n",
    "print(pseudo_id_enc_id_count.eq(1).all())\n",
    "print(\"so not all patients have a single encounter\")\n",
    "pseudo_id_enc_id_count.plot(kind=\"hist\")\n",
    "plt.xlabel(\"number of enc_id per pseudo_id\")\n",
    "plt.show()\n",
    "print(f\"{pseudo_id_enc_id_count.eq(2).sum()} patients have two encounters\")\n",
    "\n",
    "print(\"patients that have two encounters:\")\n",
    "patients_with_two_encounters = pseudo_id_enc_id_count[\n",
    "    pseudo_id_enc_id_count.eq(2)\n",
    "].index\n",
    "print(patients_with_two_encounters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lengte van opname:\n",
    "df[\"period_start\"] = pd.to_datetime(df[\"period_start\"])\n",
    "df[\"period_end\"] = pd.to_datetime(df[\"period_end\"])\n",
    "df[\"length_of_stay\"] = df[\"period_end\"] - df[\"period_start\"]\n",
    "df[\"length_of_stay\"] = df[\"length_of_stay\"].dt.days\n",
    "print(df.groupby(\"enc_id\")[\"length_of_stay\"].nunique().eq(1).all())\n",
    "print(\n",
    "    \"so all encounters have a single length of stay, which is to be expected as\"\n",
    "    + \" an encounter is a single admission\"\n",
    ")\n",
    "df.groupby([\"enc_id\"])[\"length_of_stay\"].mean().plot(kind=\"hist\", bins=50)\n",
    "plt.xlabel(\"length of stay (days)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot histograms for each category with different colors\n",
    "for category in df.department.unique():\n",
    "    subset = df[df[\"department\"] == category]\n",
    "    subset.groupby([\"enc_id\"])[\"length_of_stay\"].mean().plot(\n",
    "        kind=\"hist\", bins=50, label=category, alpha=0.2\n",
    "    )\n",
    "\n",
    "# Set labels and legend\n",
    "plt.xlabel(\"Length of Stay (days)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of Length of Stay by Location\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot histograms for each category with different colors\n",
    "for category in df.department.unique():\n",
    "    subset = df[df[\"department\"] == category]\n",
    "    subset.groupby([\"enc_id\"])[\"length_of_stay\"].mean().plot(\n",
    "        kind=\"hist\", bins=50, label=category, alpha=0.4\n",
    "    )\n",
    "\n",
    "# Set labels and legend\n",
    "plt.xlabel(\"Length of Stay (days)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of Length of Stay by Location - zoomed in\")\n",
    "plt.xlim([0, 20])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROCESSING: remove patients with a length of stay of 0\n",
    "print(f\"before removing encounters with a length of stay of 0:{df.enc_id.nunique()}\")\n",
    "df = df[df[\"length_of_stay\"] != 0]\n",
    "print(f\"after removing encounters with a length of stay of 0:{df.enc_id.nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ValueString column\n",
    "df.groupby(\"enc_id\")[\"valueString\"].nunique().plot(kind=\"hist\", bins=100)\n",
    "plt.xlabel(\"number of unique valueStrings per encounter\")\n",
    "plt.show()\n",
    "\n",
    "df.groupby(\"enc_id\")[\"valueString\"].apply(lambda x: x.str.len().mean()).plot(\n",
    "    kind=\"hist\", bins=100\n",
    ")\n",
    "plt.xlabel(\"mean length of valueString per encounter\")\n",
    "plt.show()\n",
    "df.groupby(\"enc_id\")[\"valueString\"].apply(lambda x: x.str.len().sum()).plot(\n",
    "    kind=\"hist\", bins=100\n",
    ")\n",
    "plt.xlabel(\"total length of valueString per encounter\")\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(\n",
    "    df.groupby(\"enc_id\")[\"valueString\"].apply(lambda x: x.str.len().mean()),\n",
    "    df.groupby(\"enc_id\")[\"valueString\"].apply(lambda x: x.str.len().sum()),\n",
    ")\n",
    "plt.ylabel(\"Total length of valueString per encounter\")\n",
    "plt.xlabel(\"Mean length of valueString per encounter\")\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(\n",
    "    df.groupby(\"enc_id\")[\"valueString\"].nunique(),\n",
    "    df.groupby(\"enc_id\")[\"valueString\"].apply(lambda x: x.str.len().sum()),\n",
    ")\n",
    "plt.ylabel(\"Total length of valueString per encounter\")\n",
    "plt.xlabel(\"Number of unique valueStrings per encounter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relate size of valueString to length of stay\n",
    "plt.scatter(\n",
    "    df.groupby(\"enc_id\")[\"length_of_stay\"].mean(),\n",
    "    df.groupby(\"enc_id\")[\"valueString\"].apply(lambda x: x.str.len().sum()),\n",
    ")\n",
    "plt.xlabel(\"Length of stay per encounter\")\n",
    "plt.ylabel(\"Total length of valueString per encounter\")\n",
    "plt.show()\n",
    "\n",
    "# alles van 1 dag samen is hoe veel? + samenvatting van 1 dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequentie van ingevulde statussen\n",
    "frequenties = (\n",
    "    df.groupby(\"enc_id\")\n",
    "    .apply(lambda x: x.code_display_original.value_counts() / x.length_of_stay.mean())\n",
    "    .reset_index()\n",
    ")\n",
    "frequenties.groupby(\"code_display_original\")[\"count\"].mean().sort_values(ascending=True)\n",
    "\n",
    "# neem nieuwste versie van de statussen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# op zoek naar de ontslag brief\n",
    "ontslag_docu = df[\n",
    "    df[\"code_display_original\"].isin(\n",
    "        [\"Medische Ontslagbrief - Beloop\", \"Medische ontslagbrief - Beloop Dictionary\"]\n",
    "    )\n",
    "]\n",
    "frequenties = (\n",
    "    ontslag_docu.groupby(\"enc_id\")[\"code_display_original\"].value_counts().reset_index()\n",
    ")\n",
    "print(\n",
    "    frequenties.groupby(\"code_display_original\")[\"count\"]\n",
    "    .mean()\n",
    "    .sort_values(ascending=True)\n",
    ")\n",
    "# ik vermoed nu dat het Medische Ontslagbrief - Beloop is\n",
    "medische_ontslagbrief_beloop = ontslag_docu[\n",
    "    ontslag_docu[\"code_display_original\"] == \"Medische Ontslagbrief - Beloop\"\n",
    "]\n",
    "for index in medische_ontslagbrief_beloop.index[1:2]:\n",
    "    row = medische_ontslagbrief_beloop.loc[index]\n",
    "    # print(row)\n",
    "    print(row.valueString)\n",
    "\n",
    "# heeft iedere encounter een ontslag brief?\n",
    "num_encounters_with_brief = df.groupby(\"enc_id\")[\"code_display_original\"].apply(\n",
    "    lambda x: \"Medische Ontslagbrief - Beloop\" in x.values\n",
    ").sum()\n",
    "total_encounters = df.enc_id.nunique()\n",
    "percentage_with_brief = (num_encounters_with_brief / total_encounters) * 100\n",
    "\n",
    "print(\n",
    "    f\"In {num_encounters_with_brief} van de {total_encounters} patienten \"\n",
    "    f\"({percentage_with_brief:.2f}%) was er een ontslagbrief beloop stuk in Metavision\"\n",
    ")\n",
    "# de patienten met een ontslag brief zijn:\n",
    "encounters_met_ontslag_brief = df.groupby(\"enc_id\")[\"code_display_original\"].apply(\n",
    "    lambda x: \"Medische Ontslagbrief - Beloop\" in x.values\n",
    ")\n",
    "encounters_met_ontslag_brief = encounters_met_ontslag_brief[\n",
    "    encounters_met_ontslag_brief\n",
    "].index\n",
    "print(\"Deze encounters zijn:\")\n",
    "print(encounters_met_ontslag_brief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many tokens on per encounter per day?\n",
    "df[\"nr_words\"] = df[\"valueString\"].str.split().str.len()\n",
    "df[\"nr_characters\"] = df[\"valueString\"].str.len()\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "df[\"nr_tokens\"] = df[\"valueString\"].apply(lambda x: len(encoding.encode(x)))\n",
    "\n",
    "# Create a new column with the actual encodings\n",
    "df[\"encodings\"] = df[\"valueString\"].apply(lambda x: encoding.encode(x))\n",
    "\n",
    "df[\"date\"] = df[\"period_start\"].dt.date\n",
    "# display(df)\n",
    "\n",
    "df.groupby([\"enc_id\", \"date\"])[\"nr_words\"].sum().plot(kind=\"hist\", bins=50)\n",
    "plt.xlabel(\"number of words per encounter per day\")\n",
    "plt.axvline(\n",
    "    df.groupby([\"enc_id\", \"date\"])[\"nr_words\"].sum().mean(),\n",
    "    color=\"k\",\n",
    "    linestyle=\"dashed\",\n",
    "    linewidth=1,\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "df.groupby([\"enc_id\", \"date\"])[\"nr_characters\"].sum().plot(kind=\"hist\", bins=50)\n",
    "plt.xlabel(\"number of characters per encounter per day\")\n",
    "plt.axvline(\n",
    "    df.groupby([\"enc_id\", \"date\"])[\"nr_characters\"].sum().mean(),\n",
    "    color=\"k\",\n",
    "    linestyle=\"dashed\",\n",
    "    linewidth=1,\n",
    ")\n",
    "token_limit = 4096\n",
    "plt.axvline(token_limit, color=\"r\", linestyle=\"dashed\", linewidth=1)\n",
    "plt.text(token_limit, -5, \"token limit 4096\", rotation=90)\n",
    "token_limit = 16384\n",
    "plt.axvline(token_limit, color=\"r\", linestyle=\"dashed\", linewidth=1)\n",
    "plt.text(token_limit, -5, \"token limit 16384\", rotation=90)\n",
    "plt.show()\n",
    "\n",
    "df.groupby([\"enc_id\", \"date\"])[\"nr_tokens\"].sum().plot(kind=\"hist\", bins=50)\n",
    "plt.xlabel(\"number of tokens per encounter per day\")\n",
    "plt.axvline(\n",
    "    df.groupby([\"enc_id\", \"date\"])[\"nr_tokens\"].sum().mean(),\n",
    "    color=\"k\",\n",
    "    linestyle=\"dashed\",\n",
    "    linewidth=1,\n",
    ")\n",
    "token_limit = 4096\n",
    "plt.axvline(token_limit, color=\"r\", linestyle=\"dashed\", linewidth=1)\n",
    "plt.text(token_limit, -5, \"token limit 4096\", rotation=90)\n",
    "token_limit = 16384\n",
    "plt.axvline(token_limit, color=\"r\", linestyle=\"dashed\", linewidth=1)\n",
    "plt.text(token_limit, -5, \"token limit 16384\", rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROCESSING keep only latest input for each code_display_original per effective_date\n",
    "print(f\"before removing duplicates on the same day: {df.shape}\")\n",
    "\n",
    "groupby_end_id = df.groupby([\"enc_id\", \"code_display_original\"]).mean()\n",
    "print(groupby_end_id)\n",
    "print(groupby_end_id.groupby(\"code_display_original\").mean())\n",
    "df.sort_values(by=[\"enc_id\", \"date\"], inplace=True)\n",
    "df.drop_duplicates(\n",
    "    subset=[\"enc_id\", \"date\", \"code_display_original\"], keep=\"last\", inplace=True\n",
    ")\n",
    "df.groupby(\"enc_id\").apply(lambda x: Counter(x.code_display_original))\n",
    "print(f\"after removing duplicates on the same day: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"enc_id\", \"date\"])[\"nr_characters\"].sum().plot(kind=\"hist\", bins=50)\n",
    "plt.xlabel(\"number of characters per encounter per day\")\n",
    "plt.axvline(\n",
    "    df.groupby([\"enc_id\", \"date\"])[\"nr_characters\"].sum().mean(),\n",
    "    color=\"k\",\n",
    "    linestyle=\"dashed\",\n",
    "    linewidth=1,\n",
    ")\n",
    "token_limit = 4096\n",
    "plt.axvline(token_limit, color=\"r\", linestyle=\"dashed\", linewidth=1)\n",
    "plt.text(token_limit, -5, \"token limit 4096\", rotation=90)\n",
    "token_limit = 16384\n",
    "plt.axvline(token_limit, color=\"r\", linestyle=\"dashed\", linewidth=1)\n",
    "plt.text(token_limit, -5, \"token limit 16384\", rotation=90)\n",
    "plt.show()\n",
    "\n",
    "df.groupby([\"enc_id\", \"date\"])[\"nr_tokens\"].sum().plot(kind=\"hist\", bins=50)\n",
    "plt.xlabel(\"number of tokens per encounter per day\")\n",
    "plt.axvline(\n",
    "    df.groupby([\"enc_id\", \"date\"])[\"nr_tokens\"].sum().mean(),\n",
    "    color=\"k\",\n",
    "    linestyle=\"dashed\",\n",
    "    linewidth=1,\n",
    ")\n",
    "token_limit = 4096\n",
    "plt.axvline(token_limit, color=\"r\", linestyle=\"dashed\", linewidth=1)\n",
    "plt.text(token_limit, -5, \"token limit 4096\", rotation=90)\n",
    "token_limit = 16384\n",
    "plt.axvline(token_limit, color=\"r\", linestyle=\"dashed\", linewidth=1)\n",
    "plt.text(token_limit, -5, \"token limit 16384\", rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)\n",
    "print(df.pseudo_id.unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiva_ontslag_laura",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
