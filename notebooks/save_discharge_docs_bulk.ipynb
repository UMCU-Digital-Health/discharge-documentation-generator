{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import tomli\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "from discharge_docs.dashboard.helper import (\n",
    "    get_data_from_patient_admission,\n",
    "    get_patients_from_list_names,\n",
    "    get_template_prompt,\n",
    ")\n",
    "from discharge_docs.processing.processing import (\n",
    "    get_patient_file,\n",
    ")\n",
    "from discharge_docs.prompts.prompt import (\n",
    "    load_prompts,\n",
    "    load_template_prompt,\n",
    ")\n",
    "from discharge_docs.prompts.prompt_builder import PromptBuilder\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# initialise Azure\n",
    "load_dotenv()\n",
    "TEMPERATURE = 0.2\n",
    "\n",
    "# deployment_name = \"aiva-gpt\" # GPT 3.5\n",
    "deployment_name = \"aiva-gpt4\"\n",
    "client = AzureOpenAI(\n",
    "    api_version=\"2024-02-01\",\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\", \"\"),\n",
    ")\n",
    "# load data\n",
    "df_metavision = pd.read_parquet(\n",
    "    Path.cwd().parent / \"data\" / \"processed\" / \"metavision_new_data.parquet\"\n",
    ")\n",
    "\n",
    "df_HIX = pd.read_parquet(Path.cwd().parent / \"data\" / \"processed\" / \"HiX_data.parquet\")\n",
    "\n",
    "# Define your DataFrames for each department\n",
    "df_dict = {\n",
    "    \"NICU\": df_metavision,\n",
    "    \"IC\": df_metavision,\n",
    "    \"CAR\": df_HIX,\n",
    "    \"PSY\": df_HIX,\n",
    "}\n",
    "\n",
    "\n",
    "# load used enc_ids\n",
    "with open(\n",
    "    Path.cwd().parent\n",
    "    / \"src\"\n",
    "    / \"discharge_docs\"\n",
    "    / \"dashboard\"\n",
    "    / \"enc_ids_dashboard.toml\",\n",
    "    \"rb\",\n",
    ") as f:\n",
    "    enc_ids_dict = tomli.load(f)\n",
    "    for key in enc_ids_dict:\n",
    "        enc_ids_dict[key] = enc_ids_dict[key][\"ids\"]\n",
    "\n",
    "for key in enc_ids_dict:\n",
    "    enc_ids_dict[key] = enc_ids_dict[key][:25]\n",
    "print(enc_ids_dict)\n",
    "\n",
    "data_dict, values_list = get_patients_from_list_names(df_dict, enc_ids_dict)\n",
    "\n",
    "# load prompts\n",
    "user_prompt, system_prompt = load_prompts()\n",
    "template_prompt_NICU = load_template_prompt(\"NICU\")\n",
    "template_prompt_IC = load_template_prompt(\"IC\")\n",
    "template_prompt_CAR = load_template_prompt(\"CAR\")\n",
    "template_prompt_PSY = load_template_prompt(\"PSY\")\n",
    "template_prompt_dict = {\n",
    "    \"nicu\": template_prompt_NICU,\n",
    "    \"ic\": template_prompt_IC,\n",
    "    \"car\": template_prompt_CAR,\n",
    "    \"psy\": template_prompt_PSY,\n",
    "    \"demo\": template_prompt_NICU,\n",
    "}\n",
    "\n",
    "# Load existing documents if the file exists\n",
    "try:\n",
    "    bulk_generated_docs = pd.read_csv(\n",
    "        Path.cwd().parent / \"data\" / \"processed\" / \"bulk_generated_docs_gpt4.csv\"\n",
    "    )\n",
    "except FileNotFoundError:\n",
    "    bulk_generated_docs = pd.DataFrame(columns=[\"enc_id\", \"name\", \"generated_doc\"])\n",
    "\n",
    "for selected_patient_admission in data_dict:\n",
    "    # Check if the patient's admission is listed in the generated documents\n",
    "    if selected_patient_admission in bulk_generated_docs[\"name\"].values:\n",
    "        template_prompt, department = get_template_prompt(\n",
    "            selected_patient_admission, template_prompt_dict\n",
    "        )\n",
    "        # Check if the document contains an \"Error\"\n",
    "        if (\n",
    "            \"Error\"\n",
    "            in bulk_generated_docs.loc[\n",
    "                bulk_generated_docs[\"name\"] == selected_patient_admission,\n",
    "                \"generated_doc\",\n",
    "            ].values[0]\n",
    "        ):\n",
    "            print(f\"Not skipping {selected_patient_admission}, because of error\")\n",
    "            if department == \"psy\":\n",
    "                print(\n",
    "                    f\"skipped {selected_patient_admission} anyway as not wanted dept\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "        else:\n",
    "            # If no error, skip this patient and continue to the next iteration\n",
    "            print(f\"Skipping {selected_patient_admission}\")\n",
    "            if department != \"ic\":\n",
    "                continue\n",
    "\n",
    "    print(selected_patient_admission)\n",
    "    patient_data = get_data_from_patient_admission(\n",
    "        selected_patient_admission, data_dict\n",
    "    )\n",
    "\n",
    "    prompt_builder = PromptBuilder(\n",
    "        temperature=TEMPERATURE, deployment_name=deployment_name, client=client\n",
    "    )\n",
    "\n",
    "    patient_file_string, _ = get_patient_file(patient_data)\n",
    "    discharge_letter = prompt_builder.generate_discharge_doc(\n",
    "        patient_file=patient_file_string,\n",
    "        system_prompt=system_prompt,\n",
    "        user_prompt=user_prompt,\n",
    "        template_prompt=template_prompt,\n",
    "    )\n",
    "    generated_doc = discharge_letter\n",
    "\n",
    "    if selected_patient_admission not in bulk_generated_docs[\"name\"].values:\n",
    "        new_row = pd.DataFrame(\n",
    "            {\n",
    "                \"enc_id\": [patient_data[\"enc_id\"].values[0]],\n",
    "                \"name\": [selected_patient_admission],\n",
    "                \"generated_doc\": [generated_doc],\n",
    "            }\n",
    "        )\n",
    "        bulk_generated_docs = pd.concat(\n",
    "            [bulk_generated_docs, new_row], ignore_index=True\n",
    "        )\n",
    "    else:\n",
    "        bulk_generated_docs.loc[\n",
    "            bulk_generated_docs[\"name\"] == selected_patient_admission, \"generated_doc\"\n",
    "        ] = generated_doc\n",
    "\n",
    "    bulk_generated_docs.to_csv(\n",
    "        # Path.cwd().parent / \"data\" / \"processed\" / \"bulk_generated_docs_gpt35.csv\",\n",
    "        Path.cwd().parent / \"data\" / \"processed\" / \"bulk_generated_docs_gpt4.csv\",\n",
    "        index=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pre-release data\n",
    "\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import tomli\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "from discharge_docs.dashboard.helper import (\n",
    "    get_data_from_patient_admission,\n",
    "    get_patients_from_list_names,\n",
    "    get_template_prompt,\n",
    ")\n",
    "from discharge_docs.processing.processing import (\n",
    "    get_patient_file,\n",
    ")\n",
    "from discharge_docs.prompts.prompt import (\n",
    "    load_prompts,\n",
    "    load_template_prompt,\n",
    ")\n",
    "from discharge_docs.prompts.prompt_builder import PromptBuilder\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# initialise Azure\n",
    "load_dotenv()\n",
    "TEMPERATURE = 0.2\n",
    "\n",
    "# deployment_name = \"aiva-gpt\" # GPT 3.5\n",
    "deployment_name = \"aiva-gpt4\"\n",
    "client = AzureOpenAI(\n",
    "    api_version=\"2024-02-01\",\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\", \"\"),\n",
    ")\n",
    "# load data\n",
    "df_metavision = pd.read_parquet(\n",
    "    Path.cwd().parent / \"data\" / \"processed\" / \"metavision_data_april_dp.parquet\"\n",
    ")\n",
    "\n",
    "df_HIX = pd.read_parquet(Path.cwd().parent / \"data\" / \"processed\" / \"HiX_data.parquet\")\n",
    "\n",
    "# Define your DataFrames for each department\n",
    "df_dict = {\n",
    "    \"NICU\": df_metavision,\n",
    "    \"IC\": df_metavision,\n",
    "    \"CAR\": df_HIX,\n",
    "    \"PSY\": df_HIX,\n",
    "}\n",
    "\n",
    "\n",
    "# load used enc_ids\n",
    "with open(\n",
    "    Path.cwd().parent\n",
    "    / \"src\"\n",
    "    / \"discharge_docs\"\n",
    "    / \"dashboard\"\n",
    "    / \"enc_ids_pre_release_phase1_1.toml\",\n",
    "    \"rb\",\n",
    ") as f:\n",
    "    enc_ids_dict = tomli.load(f)\n",
    "    for key in enc_ids_dict:\n",
    "        enc_ids_dict[key] = enc_ids_dict[key][\"ids\"]\n",
    "\n",
    "data_dict, values_list = get_patients_from_list_names(df_dict, enc_ids_dict)\n",
    "\n",
    "\n",
    "# load prompts\n",
    "user_prompt, system_prompt = load_prompts()\n",
    "template_prompt_NICU = load_template_prompt(\"NICU\")\n",
    "template_prompt_IC = load_template_prompt(\"IC\")\n",
    "template_prompt_CAR = load_template_prompt(\"CAR\")\n",
    "template_prompt_PSY = load_template_prompt(\"PSY\")\n",
    "template_prompt_dict = {\n",
    "    \"nicu\": template_prompt_NICU,\n",
    "    \"ic\": template_prompt_IC,\n",
    "    \"car\": template_prompt_CAR,\n",
    "    \"psy\": template_prompt_PSY,\n",
    "    \"demo\": template_prompt_NICU,\n",
    "}\n",
    "\n",
    "# Load existing documents if the file exists\n",
    "try:\n",
    "    bulk_generated_docs = pd.read_csv(\n",
    "        Path.cwd().parent / \"data\" / \"processed\" / \"bulk_generated_docs_gpt4_PReval.csv\"\n",
    "    )\n",
    "except FileNotFoundError:\n",
    "    bulk_generated_docs = pd.DataFrame(columns=[\"enc_id\", \"name\", \"generated_doc\"])\n",
    "\n",
    "for selected_patient_admission in data_dict:\n",
    "    # Check if the patient's admission is listed in the generated documents\n",
    "    if selected_patient_admission in bulk_generated_docs[\"name\"].values:\n",
    "        template_prompt, department = get_template_prompt(\n",
    "            selected_patient_admission, template_prompt_dict\n",
    "        )\n",
    "\n",
    "        # Check if the document contains an \"Error\"\n",
    "        if (\n",
    "            \"Error\"\n",
    "            in bulk_generated_docs.loc[\n",
    "                bulk_generated_docs[\"name\"] == selected_patient_admission,\n",
    "                \"generated_doc\",\n",
    "            ].values[0]\n",
    "        ):\n",
    "            print(f\"Not skipping {selected_patient_admission}, because of error\")\n",
    "\n",
    "\n",
    "        else:\n",
    "            # If no error, skip this patient and continue to the next iteration\n",
    "            print(f\"Skipping {selected_patient_admission}\")\n",
    "            continue\n",
    "            # if department != \"ic\":\n",
    "            #     continue\n",
    "    template_prompt, department = get_template_prompt(\n",
    "        selected_patient_admission, template_prompt_dict\n",
    "    )\n",
    "    print(selected_patient_admission)\n",
    "    patient_data = get_data_from_patient_admission(\n",
    "        selected_patient_admission, data_dict\n",
    "    )\n",
    "\n",
    "    prompt_builder = PromptBuilder(\n",
    "        temperature=TEMPERATURE, deployment_name=deployment_name, client=client\n",
    "    )\n",
    "\n",
    "    patient_file_string, _ = get_patient_file(patient_data)\n",
    "    discharge_letter = prompt_builder.generate_discharge_doc(\n",
    "        patient_file=patient_file_string,\n",
    "        system_prompt=system_prompt,\n",
    "        user_prompt=user_prompt,\n",
    "        template_prompt=template_prompt,\n",
    "    )\n",
    "    generated_doc = discharge_letter\n",
    "\n",
    "    if selected_patient_admission not in bulk_generated_docs[\"name\"].values:\n",
    "        new_row = pd.DataFrame(\n",
    "            {\n",
    "                \"enc_id\": [patient_data[\"enc_id\"].values[0]],\n",
    "                \"name\": [selected_patient_admission],\n",
    "                \"generated_doc\": [generated_doc],\n",
    "            }\n",
    "        )\n",
    "        bulk_generated_docs = pd.concat(\n",
    "            [bulk_generated_docs, new_row], ignore_index=True\n",
    "        )\n",
    "    else:\n",
    "        bulk_generated_docs.loc[\n",
    "            bulk_generated_docs[\"name\"] == selected_patient_admission, \"generated_doc\"\n",
    "        ] = generated_doc\n",
    "\n",
    "    bulk_generated_docs.to_csv(\n",
    "        Path.cwd().parent\n",
    "        / \"data\"\n",
    "        / \"processed\"\n",
    "        / \"bulk_generated_docs_gpt4_PReval.csv\",\n",
    "        index=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre release phase 1 part 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pre-release data\n",
    "\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import tomli\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "from discharge_docs.dashboard.helper import (\n",
    "    get_data_from_patient_admission,\n",
    "    get_patients_from_list_names_pilot,\n",
    "    get_template_prompt,\n",
    ")\n",
    "from discharge_docs.processing.processing import (\n",
    "    get_patient_file,\n",
    ")\n",
    "from discharge_docs.prompts.prompt import (\n",
    "    load_prompts,\n",
    "    load_template_prompt,\n",
    ")\n",
    "from discharge_docs.prompts.prompt_builder import PromptBuilder\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# initialise Azure\n",
    "load_dotenv()\n",
    "TEMPERATURE = 0.2\n",
    "\n",
    "# deployment_name = \"aiva-gpt\" # GPT 3.5\n",
    "deployment_name = \"aiva-gpt4\"\n",
    "client = AzureOpenAI(\n",
    "    api_version=\"2024-02-01\",\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\", \"\"),\n",
    ")\n",
    "# load data\n",
    "df_metavision = pd.read_parquet(\n",
    "    Path.cwd().parent / \"data\" / \"processed\" / \"metavision_data_april_dp.parquet\"\n",
    ")\n",
    "\n",
    "df_HIX = pd.read_parquet(Path.cwd().parent / \"data\" / \"processed\" / \"HiX_data.parquet\")\n",
    "\n",
    "# Define your DataFrames for each department\n",
    "df_dict = {\n",
    "    \"NICU\": df_metavision,\n",
    "    \"IC\": df_metavision,\n",
    "    \"CAR\": df_HIX,\n",
    "    \"PSY\": df_HIX,\n",
    "}\n",
    "\n",
    "\n",
    "# load used enc_ids\n",
    "with open(\n",
    "    Path.cwd().parent\n",
    "    / \"src\"\n",
    "    / \"discharge_docs\"\n",
    "    / \"dashboard\"\n",
    "    / \"enc_ids_pre_release_phase1_1.toml\",\n",
    "    \"rb\",\n",
    ") as f:\n",
    "    enc_ids_dict = tomli.load(f)\n",
    "    id_dep_dict = {}\n",
    "    for key in enc_ids_dict:\n",
    "        id_dep_dict[key] = list(\n",
    "            zip(enc_ids_dict[key][\"ids\"], enc_ids_dict[key][\"department\"], strict=False)\n",
    "        )\n",
    "\n",
    "data_dict, values_list = get_patients_from_list_names_pilot(df_dict, id_dep_dict)\n",
    "\n",
    "\n",
    "# load prompts\n",
    "user_prompt, system_prompt = load_prompts()\n",
    "template_prompt_NICU = load_template_prompt(\"NICU\")\n",
    "template_prompt_IC = load_template_prompt(\"IC\")\n",
    "template_prompt_CAR = load_template_prompt(\"CAR\")\n",
    "template_prompt_PSY = load_template_prompt(\"PSY\")\n",
    "template_prompt_dict = {\n",
    "    \"nicu\": template_prompt_NICU,\n",
    "    \"ic\": template_prompt_IC,\n",
    "    \"car\": template_prompt_CAR,\n",
    "    \"psy\": template_prompt_PSY,\n",
    "    \"demo\": template_prompt_NICU,\n",
    "}\n",
    "\n",
    "# Load existing documents if the file exists\n",
    "try:\n",
    "    bulk_generated_docs = pd.read_csv(\n",
    "        Path.cwd().parent / \"data\" / \"processed\" / \"bulk_generated_docs_gpt4_PReval_2.csv\"\n",
    "    )\n",
    "except FileNotFoundError:\n",
    "    bulk_generated_docs = pd.DataFrame(columns=[\"enc_id\", \"name\", \"generated_doc\"])\n",
    "\n",
    "for selected_patient_admission in data_dict:\n",
    "    # Check if the patient's admission is listed in the generated documents\n",
    "    if selected_patient_admission in bulk_generated_docs[\"name\"].values:\n",
    "        template_prompt, department = get_template_prompt(\n",
    "            selected_patient_admission.rsplit('_', 1)[0], template_prompt_dict\n",
    "        )\n",
    "\n",
    "        # Check if the document contains an \"Error\"\n",
    "        if (\n",
    "            \"Error\"\n",
    "            in bulk_generated_docs.loc[\n",
    "                bulk_generated_docs[\"name\"] == selected_patient_admission,\n",
    "                \"generated_doc\",\n",
    "            ].values[0]\n",
    "        ):\n",
    "            print(f\"Not skipping {selected_patient_admission}, because of error\")\n",
    "\n",
    "\n",
    "        else:\n",
    "            # If no error, skip this patient and continue to the next iteration\n",
    "            print(f\"Skipping {selected_patient_admission}\")\n",
    "            continue\n",
    "            # if department != \"ic\":\n",
    "            #     continue\n",
    "    template_prompt, department = get_template_prompt(\n",
    "        selected_patient_admission.rsplit('_', 1)[0], template_prompt_dict\n",
    "    )\n",
    "    print(selected_patient_admission)\n",
    "    patient_data = get_data_from_patient_admission(\n",
    "        selected_patient_admission, data_dict\n",
    "    )\n",
    "\n",
    "    prompt_builder = PromptBuilder(\n",
    "        temperature=TEMPERATURE, deployment_name=deployment_name, client=client\n",
    "    )\n",
    "\n",
    "    patient_file_string, _ = get_patient_file(patient_data)\n",
    "    discharge_letter = prompt_builder.generate_discharge_doc(\n",
    "        patient_file=patient_file_string,\n",
    "        system_prompt=system_prompt,\n",
    "        user_prompt=user_prompt,\n",
    "        template_prompt=template_prompt,\n",
    "    )\n",
    "    generated_doc = discharge_letter\n",
    "\n",
    "    if selected_patient_admission not in bulk_generated_docs[\"name\"].values:\n",
    "        new_row = pd.DataFrame(\n",
    "            {\n",
    "                \"enc_id\": [patient_data[\"enc_id\"].values[0]],\n",
    "                \"name\": [selected_patient_admission],\n",
    "                \"generated_doc\": [generated_doc],\n",
    "            }\n",
    "        )\n",
    "        bulk_generated_docs = pd.concat(\n",
    "            [bulk_generated_docs, new_row], ignore_index=True\n",
    "        )\n",
    "    else:\n",
    "        bulk_generated_docs.loc[\n",
    "            bulk_generated_docs[\"name\"] == selected_patient_admission, \"generated_doc\"\n",
    "        ] = generated_doc\n",
    "\n",
    "    bulk_generated_docs.to_csv(\n",
    "        Path.cwd().parent\n",
    "        / \"data\"\n",
    "        / \"processed\"\n",
    "        / \"bulk_generated_docs_gpt4_PReval_2.csv\",\n",
    "        index=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-release phase 1 part 3: Cardio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pre-release data\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import tomli\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "from discharge_docs.dashboard.helper import (\n",
    "    get_data_from_patient_admission,\n",
    "    get_patients_from_list_names_pilot,\n",
    "    get_template_prompt,\n",
    ")\n",
    "from discharge_docs.processing.processing import (\n",
    "    get_patient_file,\n",
    ")\n",
    "from discharge_docs.prompts.prompt import (\n",
    "    load_prompts,\n",
    "    load_template_prompt,\n",
    ")\n",
    "from discharge_docs.prompts.prompt_builder import PromptBuilder\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# initialise Azure\n",
    "load_dotenv()\n",
    "TEMPERATURE = 0.2\n",
    "\n",
    "# deployment_name = \"aiva-gpt\" # GPT 3.5\n",
    "deployment_name = \"aiva-gpt4\"\n",
    "client = AzureOpenAI(\n",
    "    api_version=\"2024-02-01\",\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\", \"\"),\n",
    ")\n",
    "# load data\n",
    "df_metavision = pd.read_parquet(\n",
    "    Path.cwd().parent / \"data\" / \"processed\" / \"metavision_data_april_dp.parquet\"\n",
    ")\n",
    "\n",
    "df_HIX = pd.read_parquet(Path.cwd().parent / \"data\" / \"processed\" / \"HiX_CAR_data_pre_pilot.parquet\")\n",
    "\n",
    "# Define your DataFrames for each department\n",
    "df_dict = {\n",
    "    \"NICU\": df_metavision,\n",
    "    \"IC\": df_metavision,\n",
    "    \"CAR\": df_HIX,\n",
    "    \"PSY\": df_HIX,\n",
    "}\n",
    "\n",
    "\n",
    "# load used enc_ids\n",
    "with open(\n",
    "    Path.cwd().parent\n",
    "    / \"src\"\n",
    "    / \"discharge_docs\"\n",
    "    / \"dashboard\"\n",
    "    / \"enc_ids_pre_release_phase1_1.toml\",\n",
    "    \"rb\",\n",
    ") as f:\n",
    "    enc_ids_dict = tomli.load(f)\n",
    "    id_dep_dict = {}\n",
    "    for key in enc_ids_dict:\n",
    "        id_dep_dict[key] = list(\n",
    "            zip(enc_ids_dict[key][\"ids\"], enc_ids_dict[key][\"department\"], strict=False)\n",
    "        )\n",
    "\n",
    "data_dict, values_list = get_patients_from_list_names_pilot(df_dict, id_dep_dict)\n",
    "\n",
    "\n",
    "# load prompts\n",
    "user_prompt, system_prompt = load_prompts()\n",
    "template_prompt_NICU = load_template_prompt(\"NICU\")\n",
    "template_prompt_IC = load_template_prompt(\"IC\")\n",
    "template_prompt_CAR = load_template_prompt(\"CAR\")\n",
    "template_prompt_PSY = load_template_prompt(\"PSY\")\n",
    "template_prompt_dict = {\n",
    "    \"nicu\": template_prompt_NICU,\n",
    "    \"ic\": template_prompt_IC,\n",
    "    \"car\": template_prompt_CAR,\n",
    "    \"psy\": template_prompt_PSY,\n",
    "    \"demo\": template_prompt_NICU,\n",
    "}\n",
    "\n",
    "# Load existing documents if the file exists\n",
    "try:\n",
    "    bulk_generated_docs = pd.read_csv(\n",
    "        Path.cwd().parent / \"data\" / \"processed\" / \"bulk_generated_docs_gpt4_PReval_3.csv\"\n",
    "    )\n",
    "except FileNotFoundError:\n",
    "    bulk_generated_docs = pd.DataFrame(columns=[\"enc_id\", \"name\", \"generated_doc\"])\n",
    "\n",
    "for selected_patient_admission in data_dict:\n",
    "    # Check if the patient's admission is listed in the generated documents\n",
    "    if selected_patient_admission in bulk_generated_docs[\"name\"].values:\n",
    "        template_prompt, department = get_template_prompt(\n",
    "            selected_patient_admission.rsplit('_', 1)[0], template_prompt_dict\n",
    "        )\n",
    "\n",
    "        # Check if the document contains an \"Error\"\n",
    "        if (\n",
    "            \"Error\"\n",
    "            in bulk_generated_docs.loc[\n",
    "                bulk_generated_docs[\"name\"] == selected_patient_admission,\n",
    "                \"generated_doc\",\n",
    "            ].values[0]\n",
    "        ):\n",
    "            print(f\"Not skipping {selected_patient_admission}, because of error\")\n",
    "\n",
    "\n",
    "        else:\n",
    "            # If no error, skip this patient and continue to the next iteration\n",
    "            print(f\"Skipping {selected_patient_admission}\")\n",
    "            continue\n",
    "            # if department != \"ic\":\n",
    "            #     continue\n",
    "    template_prompt, department = get_template_prompt(\n",
    "        selected_patient_admission.rsplit('_', 1)[0], template_prompt_dict\n",
    "    )\n",
    "    print(selected_patient_admission)\n",
    "    patient_data = get_data_from_patient_admission(\n",
    "        selected_patient_admission, data_dict\n",
    "    )\n",
    "\n",
    "    prompt_builder = PromptBuilder(\n",
    "        temperature=TEMPERATURE, deployment_name=deployment_name, client=client\n",
    "    )\n",
    "\n",
    "    patient_file_string, _ = get_patient_file(patient_data)\n",
    "    discharge_letter = prompt_builder.generate_discharge_doc(\n",
    "        patient_file=patient_file_string,\n",
    "        system_prompt=system_prompt,\n",
    "        user_prompt=user_prompt,\n",
    "        template_prompt=template_prompt,\n",
    "    )\n",
    "    generated_doc = discharge_letter\n",
    "\n",
    "    if selected_patient_admission not in bulk_generated_docs[\"name\"].values:\n",
    "        new_row = pd.DataFrame(\n",
    "            {\n",
    "                \"enc_id\": [patient_data[\"enc_id\"].values[0]],\n",
    "                \"name\": [selected_patient_admission],\n",
    "                \"generated_doc\": [generated_doc],\n",
    "            }\n",
    "        )\n",
    "        bulk_generated_docs = pd.concat(\n",
    "            [bulk_generated_docs, new_row], ignore_index=True\n",
    "        )\n",
    "    else:\n",
    "        bulk_generated_docs.loc[\n",
    "            bulk_generated_docs[\"name\"] == selected_patient_admission, \"generated_doc\"\n",
    "        ] = generated_doc\n",
    "\n",
    "    bulk_generated_docs.to_csv(\n",
    "        Path.cwd().parent\n",
    "        / \"data\"\n",
    "        / \"processed\"\n",
    "        / \"bulk_generated_docs_gpt4_PReval_3.csv\",\n",
    "        index=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-release phase 1 part 4: additional Cardio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pre-release data\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import tomli\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "from discharge_docs.dashboard.helper import (\n",
    "    get_data_from_patient_admission,\n",
    "    get_patients_from_list_names_pilot,\n",
    "    get_template_prompt,\n",
    ")\n",
    "from discharge_docs.processing.processing import (\n",
    "    get_patient_file,\n",
    ")\n",
    "from discharge_docs.prompts.prompt import (\n",
    "    load_prompts,\n",
    "    load_template_prompt,\n",
    ")\n",
    "from discharge_docs.prompts.prompt_builder import PromptBuilder\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# initialise Azure\n",
    "load_dotenv()\n",
    "TEMPERATURE = 0.2\n",
    "\n",
    "# deployment_name = \"aiva-gpt\" # GPT 3.5\n",
    "deployment_name = \"aiva-gpt4\"\n",
    "client = AzureOpenAI(\n",
    "    api_version=\"2024-02-01\",\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\", \"\"),\n",
    ")\n",
    "# load data\n",
    "df_metavision = pd.read_parquet(\n",
    "    Path.cwd().parent / \"data\" / \"processed\" / \"metavision_data_april_dp.parquet\"\n",
    ")\n",
    "\n",
    "df_HIX = pd.read_parquet(Path.cwd().parent / \"data\" / \"processed\" / \"HiX_CAR_data_pre_pilot.parquet\")\n",
    "\n",
    "# Define your DataFrames for each department\n",
    "df_dict = {\n",
    "    \"NICU\": df_metavision,\n",
    "    \"IC\": df_metavision,\n",
    "    \"CAR\": df_HIX,\n",
    "    \"PSY\": df_HIX,\n",
    "}\n",
    "\n",
    "\n",
    "# load used enc_ids\n",
    "with open(\n",
    "    Path.cwd().parent\n",
    "    / \"src\"\n",
    "    / \"discharge_docs\"\n",
    "    / \"dashboard\"\n",
    "    / \"enc_ids_pre_release_phase1_1.toml\",\n",
    "    \"rb\",\n",
    ") as f:\n",
    "    enc_ids_dict = tomli.load(f)\n",
    "    id_dep_dict = {}\n",
    "    for key in enc_ids_dict:\n",
    "        id_dep_dict[key] = list(\n",
    "            zip(enc_ids_dict[key][\"ids\"], enc_ids_dict[key][\"department\"], strict=False)\n",
    "        )\n",
    "\n",
    "data_dict, values_list = get_patients_from_list_names_pilot(df_dict, id_dep_dict)\n",
    "\n",
    "\n",
    "# load prompts\n",
    "user_prompt, system_prompt = load_prompts()\n",
    "template_prompt_NICU = load_template_prompt(\"NICU\")\n",
    "template_prompt_IC = load_template_prompt(\"IC\")\n",
    "template_prompt_CAR = load_template_prompt(\"CAR\")\n",
    "template_prompt_PSY = load_template_prompt(\"PSY\")\n",
    "template_prompt_dict = {\n",
    "    \"nicu\": template_prompt_NICU,\n",
    "    \"ic\": template_prompt_IC,\n",
    "    \"car\": template_prompt_CAR,\n",
    "    \"psy\": template_prompt_PSY,\n",
    "    \"demo\": template_prompt_NICU,\n",
    "}\n",
    "\n",
    "# Load existing documents if the file exists\n",
    "try:\n",
    "    bulk_generated_docs = pd.read_csv(\n",
    "        Path.cwd().parent / \"data\" / \"processed\" / \"bulk_generated_docs_gpt4_PReval_4.csv\"\n",
    "    )\n",
    "except FileNotFoundError:\n",
    "    bulk_generated_docs = pd.DataFrame(columns=[\"enc_id\", \"name\", \"generated_doc\"])\n",
    "\n",
    "for selected_patient_admission in data_dict:\n",
    "    # Check if the patient's admission is listed in the generated documents\n",
    "    if selected_patient_admission in bulk_generated_docs[\"name\"].values:\n",
    "        template_prompt, department = get_template_prompt(\n",
    "            selected_patient_admission.rsplit('_', 1)[0], template_prompt_dict\n",
    "        )\n",
    "\n",
    "        # Check if the document contains an \"Error\"\n",
    "        if (\n",
    "            \"Error\"\n",
    "            in bulk_generated_docs.loc[\n",
    "                bulk_generated_docs[\"name\"] == selected_patient_admission,\n",
    "                \"generated_doc\",\n",
    "            ].values[0]\n",
    "        ):\n",
    "            print(f\"Not skipping {selected_patient_admission}, because of error\")\n",
    "\n",
    "\n",
    "        else:\n",
    "            # If no error, skip this patient and continue to the next iteration\n",
    "            print(f\"Skipping {selected_patient_admission}\")\n",
    "            continue\n",
    "            # if department != \"ic\":\n",
    "            #     continue\n",
    "    template_prompt, department = get_template_prompt(\n",
    "        selected_patient_admission.rsplit('_', 1)[0], template_prompt_dict\n",
    "    )\n",
    "    print(selected_patient_admission)\n",
    "    patient_data = get_data_from_patient_admission(\n",
    "        selected_patient_admission, data_dict\n",
    "    )\n",
    "\n",
    "    prompt_builder = PromptBuilder(\n",
    "        temperature=TEMPERATURE, deployment_name=deployment_name, client=client\n",
    "    )\n",
    "\n",
    "    patient_file_string, _ = get_patient_file(patient_data)\n",
    "    discharge_letter = prompt_builder.generate_discharge_doc(\n",
    "        patient_file=patient_file_string,\n",
    "        system_prompt=system_prompt,\n",
    "        user_prompt=user_prompt,\n",
    "        template_prompt=template_prompt,\n",
    "    )\n",
    "    generated_doc = discharge_letter\n",
    "\n",
    "    if selected_patient_admission not in bulk_generated_docs[\"name\"].values:\n",
    "        new_row = pd.DataFrame(\n",
    "            {\n",
    "                \"enc_id\": [patient_data[\"enc_id\"].values[0]],\n",
    "                \"name\": [selected_patient_admission],\n",
    "                \"generated_doc\": [generated_doc],\n",
    "            }\n",
    "        )\n",
    "        bulk_generated_docs = pd.concat(\n",
    "            [bulk_generated_docs, new_row], ignore_index=True\n",
    "        )\n",
    "    else:\n",
    "        bulk_generated_docs.loc[\n",
    "            bulk_generated_docs[\"name\"] == selected_patient_admission, \"generated_doc\"\n",
    "        ] = generated_doc\n",
    "\n",
    "    bulk_generated_docs.to_csv(\n",
    "        Path.cwd().parent\n",
    "        / \"data\"\n",
    "        / \"processed\"\n",
    "        / \"bulk_generated_docs_gpt4_PReval_4.csv\",\n",
    "        index=False,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
